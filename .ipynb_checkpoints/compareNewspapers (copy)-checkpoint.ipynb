{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# for pretty code\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# for pretty code\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for pretty code\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# imports\\nimport numpy as np\\nimport pandas as pd\\nimport statsmodels.api as sm\\nimport multiprocessing as mp\\n\\nfrom newsrelations.query_db.relation_query import DBQueryHandlerCoocc\\nfrom newsrelations.helper_classes.synonym_handler import SynonymHandler\\nfrom newsrelations.metrics.distances import DistanceMeasure\";\n",
       "                var nbb_formatted_code = \"# imports\\nimport numpy as np\\nimport pandas as pd\\nimport statsmodels.api as sm\\nimport multiprocessing as mp\\n\\nfrom newsrelations.query_db.relation_query import DBQueryHandlerCoocc\\nfrom newsrelations.helper_classes.synonym_handler import SynonymHandler\\nfrom newsrelations.metrics.distances import DistanceMeasure\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import multiprocessing as mp\n",
    "\n",
    "from newsrelations.query_db.relation_query import DBQueryHandlerCoocc\n",
    "from newsrelations.helper_classes.synonym_handler import SynonymHandler\n",
    "from newsrelations.metrics.distances import DistanceMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def build_contingency_table_from_single_topic(\\n    relation_models_path, relation_models, topic_of_interest, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic [TOPIC_OF_INTEREST].\\n    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\\n    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest = str           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest, cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(relation_models[0])],\\n    )\\n\\n    # loop through all remaining models\\n    for model in relation_models[1:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        # buffer for cooccurrences\\n        co_occs = []\\n        # loop through all entities and get number of co-occurrences\\n        for row in contingency_table.index:\\n            co_occs.append(\\n                len(\\n                    list(\\n                        db_handler.select_relations(\\n                            e1=topic_of_interest.lower(),\\n                            e2=row.lower(),\\n                            e1_is_synset=0,\\n                            e2_is_synset=0,\\n                        )\\n                    )\\n                )\\n            )\\n\\n        contingency_table[str(model)] = co_occs\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def build_contingency_table_from_single_topic(\\n    relation_models_path, relation_models, topic_of_interest, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic [TOPIC_OF_INTEREST].\\n    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\\n    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest = str           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest, cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(relation_models[0])],\\n    )\\n\\n    # loop through all remaining models\\n    for model in relation_models[1:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        # buffer for cooccurrences\\n        co_occs = []\\n        # loop through all entities and get number of co-occurrences\\n        for row in contingency_table.index:\\n            co_occs.append(\\n                len(\\n                    list(\\n                        db_handler.select_relations(\\n                            e1=topic_of_interest.lower(),\\n                            e2=row.lower(),\\n                            e1_is_synset=0,\\n                            e2_is_synset=0,\\n                        )\\n                    )\\n                )\\n            )\\n\\n        contingency_table[str(model)] = co_occs\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_contingency_table_from_single_topic(\n",
    "    relation_models_path, relation_models, topic_of_interest, no_entities=10\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined topic [TOPIC_OF_INTEREST].\n",
    "    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_of_interest = str           \n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # initialize DistanceMeasure with reference-model\n",
    "    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest, cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\n",
    "    )\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(\n",
    "        np.array([t[1] for t in top]),\n",
    "        index=[t[0] for t in top],\n",
    "        columns=[str(relation_models[0])],\n",
    "    )\n",
    "\n",
    "    # loop through all remaining models\n",
    "    for model in relation_models[1:]:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        # buffer for cooccurrences\n",
    "        co_occs = []\n",
    "        # loop through all entities and get number of co-occurrences\n",
    "        for row in contingency_table.index:\n",
    "            co_occs.append(\n",
    "                len(\n",
    "                    list(\n",
    "                        db_handler.select_relations(\n",
    "                            e1=topic_of_interest.lower(),\n",
    "                            e2=row.lower(),\n",
    "                            e1_is_synset=0,\n",
    "                            e2_is_synset=0,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        contingency_table[str(model)] = co_occs\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def explain_models(relation_models):\\n    \\\"\\\"\\\"\\n    This function lists the models from the relation_models list and their counter index\\n    \\n    Input: relation_models = list\\n    \\n    Output: None\\n    \\\"\\\"\\\"\\n    i = 0\\n    for model in relation_models:\\n        print(\\\"model(\\\" + str(i) + \\\"): \\\" + str(model))\\n        i += 1\\n    return\";\n",
       "                var nbb_formatted_code = \"def explain_models(relation_models):\\n    \\\"\\\"\\\"\\n    This function lists the models from the relation_models list and their counter index\\n    \\n    Input: relation_models = list\\n    \\n    Output: None\\n    \\\"\\\"\\\"\\n    i = 0\\n    for model in relation_models:\\n        print(\\\"model(\\\" + str(i) + \\\"): \\\" + str(model))\\n        i += 1\\n    return\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explain_models(relation_models):\n",
    "    \"\"\"\n",
    "    This function lists the models from the relation_models list and their counter index\n",
    "    \n",
    "    Input: relation_models = list\n",
    "    \n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for model in relation_models:\n",
    "        print(\"model(\" + str(i) + \"): \" + str(model))\n",
    "        i += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def build_contingency_table_from_topic_list(\\n    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic list [topic_of_interest_list].\\n    The first model in [relation_models] is the reference model all other models will be compared with.\\n    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \\n    model and builds a contingency table.\\n    \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest_list = list           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # identifier for models in relation_models_list\\n    i = 0\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(topic_of_interest_list[0]) + \\\" (\\\" + str(i) + \\\")\\\"],\\n    )\\n\\n    # loop through the models\\n    for model in relation_models[:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic in topic_of_interest_list:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for row in contingency_table.index:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic.lower(),\\n                                e2=row.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def build_contingency_table_from_topic_list(\\n    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic list [topic_of_interest_list].\\n    The first model in [relation_models] is the reference model all other models will be compared with.\\n    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \\n    model and builds a contingency table.\\n    \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest_list = list           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # identifier for models in relation_models_list\\n    i = 0\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(topic_of_interest_list[0]) + \\\" (\\\" + str(i) + \\\")\\\"],\\n    )\\n\\n    # loop through the models\\n    for model in relation_models[:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic in topic_of_interest_list:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for row in contingency_table.index:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic.lower(),\\n                                e2=row.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_contingency_table_from_topic_list(\n",
    "    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined topic list [topic_of_interest_list].\n",
    "    The first model in [relation_models] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \n",
    "    model and builds a contingency table.\n",
    "    \n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_of_interest_list = list           \n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # identifier for models in relation_models_list\n",
    "    i = 0\n",
    "    # print models with idx\n",
    "    explain_models(relation_models)\n",
    "\n",
    "    # initialize DistanceMeasure with reference-model\n",
    "    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\n",
    "    )\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(\n",
    "        np.array([t[1] for t in top]),\n",
    "        index=[t[0] for t in top],\n",
    "        columns=[str(topic_of_interest_list[0]) + \" (\" + str(i) + \")\"],\n",
    "    )\n",
    "\n",
    "    # loop through the models\n",
    "    for model in relation_models[:]:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        for topic in topic_of_interest_list:\n",
    "            # buffer for co-occurrencces\n",
    "            co_occs = []\n",
    "\n",
    "            # loop through all all entities and get number of co-occurrences\n",
    "            for row in contingency_table.index:\n",
    "                co_occs.append(\n",
    "                    len(\n",
    "                        list(\n",
    "                            db_handler.select_relations(\n",
    "                                e1=topic.lower(),\n",
    "                                e2=row.lower(),\n",
    "                                e1_is_synset=0,\n",
    "                                e2_is_synset=0,\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            contingency_table[str(topic) + \" (\" + str(i) + \")\"] = co_occs\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def compare_entity_lists(\\n    relation_models_path, relation_models, topic_list1, topic_list2\\n):\\n    \\\"\\\"\\\"\\n    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\\n    from a list of relation models \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_list1 = list           \\n            topic_list2 = list\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # idx for models\\n    i = 0\\n\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize contingency_table\\n    contingency_table = pd.DataFrame(index=topic_list2)\\n\\n    # loop through the models\\n    for model in relation_models:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic1 in topic_list1:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for topic2 in topic_list2:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic1.lower(),\\n                                e2=topic2.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic1) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def compare_entity_lists(\\n    relation_models_path, relation_models, topic_list1, topic_list2\\n):\\n    \\\"\\\"\\\"\\n    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\\n    from a list of relation models \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_list1 = list           \\n            topic_list2 = list\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # idx for models\\n    i = 0\\n\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize contingency_table\\n    contingency_table = pd.DataFrame(index=topic_list2)\\n\\n    # loop through the models\\n    for model in relation_models:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic1 in topic_list1:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for topic2 in topic_list2:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic1.lower(),\\n                                e2=topic2.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic1) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_entity_lists(\n",
    "    relation_models_path, relation_models, topic_list1, topic_list2\n",
    "):\n",
    "    \"\"\"\n",
    "    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\n",
    "    from a list of relation models \n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_list1 = list           \n",
    "            topic_list2 = list\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # idx for models\n",
    "    i = 0\n",
    "\n",
    "    # print models with idx\n",
    "    explain_models(relation_models)\n",
    "\n",
    "    # initialize contingency_table\n",
    "    contingency_table = pd.DataFrame(index=topic_list2)\n",
    "\n",
    "    # loop through the models\n",
    "    for model in relation_models:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        for topic1 in topic_list1:\n",
    "            # buffer for co-occurrencces\n",
    "            co_occs = []\n",
    "\n",
    "            # loop through all all entities and get number of co-occurrences\n",
    "            for topic2 in topic_list2:\n",
    "                co_occs.append(\n",
    "                    len(\n",
    "                        list(\n",
    "                            db_handler.select_relations(\n",
    "                                e1=topic1.lower(),\n",
    "                                e2=topic2.lower(),\n",
    "                                e1_is_synset=0,\n",
    "                                e2_is_synset=0,\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            contingency_table[str(topic1) + \" (\" + str(i) + \")\"] = co_occs\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def chi_squared(contingency_table, print_orig = False, print_expect = False, print_chi_contr = False):\\n    \\\"\\\"\\\"\\n    This function conducts a chi-squared test of independence between the different rows of a contingency table\\n    \\n    input: contingency_table\\n    \\n    ouput: None\\n    \\\"\\\"\\\"\\n    contingency_table = sm.stats.Table(contingency_table)\\n    results = contingency_table.test_nominal_association()\\n    \\n    \\n    # orig contingency table\\n    if print_orig == True:\\n        print(\\\"Original contingency table:\\\")\\n        print(contingency_table.table_orig)\\n    # expected values\\n    if print_expect == True:\\n        print(\\\"\\\\nExpected values:\\\")\\n        print(contingency_table.fittedvalues)\\n    # chi-squared contributions\\n    if print_chi_contr == True:\\n        print(\\\"\\\\nChi-square contributions:\\\")\\n        print(contingency_table.chi2_contribs)\\n    \\n    # results\\n    print(\\\"\\\\nResults:\\\")\\n    print(results.pvalue)\\n    print(results.statistic)\\n    \\n    \\n    results = contingency_table.test_ordinal_association()\\n    #print(\\\"\\\\nOrdinal test results:\\\")\\n    #print(results)\\n    \\n    return\";\n",
       "                var nbb_formatted_code = \"def chi_squared(\\n    contingency_table, print_orig=False, print_expect=False, print_chi_contr=False\\n):\\n    \\\"\\\"\\\"\\n    This function conducts a chi-squared test of independence between the different rows of a contingency table\\n    \\n    input: contingency_table\\n    \\n    ouput: None\\n    \\\"\\\"\\\"\\n    contingency_table = sm.stats.Table(contingency_table)\\n    results = contingency_table.test_nominal_association()\\n\\n    # orig contingency table\\n    if print_orig == True:\\n        print(\\\"Original contingency table:\\\")\\n        print(contingency_table.table_orig)\\n    # expected values\\n    if print_expect == True:\\n        print(\\\"\\\\nExpected values:\\\")\\n        print(contingency_table.fittedvalues)\\n    # chi-squared contributions\\n    if print_chi_contr == True:\\n        print(\\\"\\\\nChi-square contributions:\\\")\\n        print(contingency_table.chi2_contribs)\\n\\n    # results\\n    print(\\\"\\\\nResults:\\\")\\n    print(results.pvalue)\\n    print(results.statistic)\\n\\n    results = contingency_table.test_ordinal_association()\\n    # print(\\\"\\\\nOrdinal test results:\\\")\\n    # print(results)\\n\\n    return\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chi_squared(contingency_table, print_orig = False, print_expect = False, print_chi_contr = False):\n",
    "    \"\"\"\n",
    "    This function conducts a chi-squared test of independence between the different rows of a contingency table\n",
    "    \n",
    "    input: contingency_table\n",
    "    \n",
    "    ouput: None\n",
    "    \"\"\"\n",
    "    contingency_table = sm.stats.Table(contingency_table)\n",
    "    results = contingency_table.test_nominal_association()\n",
    "    \n",
    "    \n",
    "    # orig contingency table\n",
    "    if print_orig == True:\n",
    "        print(\"Original contingency table:\")\n",
    "        print(contingency_table.table_orig)\n",
    "    # expected values\n",
    "    if print_expect == True:\n",
    "        print(\"\\nExpected values:\")\n",
    "        print(contingency_table.fittedvalues)\n",
    "    # chi-squared contributions\n",
    "    if print_chi_contr == True:\n",
    "        print(\"\\nChi-square contributions:\")\n",
    "        print(contingency_table.chi2_contribs)\n",
    "    \n",
    "    # results\n",
    "    print(\"\\nResults:\")\n",
    "    print(results.pvalue)\n",
    "    print(results.statistic)\n",
    "    \n",
    "    \n",
    "    results = contingency_table.test_ordinal_association()\n",
    "    #print(\"\\nOrdinal test results:\")\n",
    "    #print(results)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "Variable setups for different runs of models (all scraped from commoncrawl.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# First Try\\n# general tryout on the NewsRelations Library\\n\\n# directory path of relation models\\nRELATION_MODELS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/models/firstTry\\\"\\n\\n# model name\\nRELATION_MODELS = [\\n    \\\"model.sqlite\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"# First Try\\n# general tryout on the NewsRelations Library\\n\\n# directory path of relation models\\nRELATION_MODELS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/models/firstTry\\\"\\n\\n# model name\\nRELATION_MODELS = [\\n    \\\"model.sqlite\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First Try\n",
    "# general tryout on the NewsRelations Library\n",
    "\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/firstTry\"\n",
    "\n",
    "# model name\n",
    "RELATION_MODELS = [\n",
    "    \"model.sqlite\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Try\n",
    "# models from newssources with different biases \n",
    "#\n",
    "# -year:    2008 (for foxnews 2o08-2010)\n",
    "# -domain:  politics\n",
    "# -sources: NYT & foxnews \n",
    "\n",
    "# directory path of relation models \n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/secondTry\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RMadvanced_2008_politics_nytimes.sqlite\",\n",
    "    \"RM_2009_politics_nytimes.sqlite\",\n",
    "    \"RM_2008-2010_politics_foxnews.sqlite\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Try\n",
    "# models from newssources with different biases \n",
    "#\n",
    "# -year:    2011\n",
    "# -domain:  news\n",
    "# -sources: reuters & national public radio\n",
    "\n",
    "# directory path of relation models \n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/thirdTry\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2011_news_reuters.sqlite\",\n",
    "    \"RM_2011_news_npr.sqlite\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Fourth try\\n# two models from newssources with different biases each, for comparing slant coherence within\\n# different directions. Timeslots with gapless news reporting were chosen.\\n#\\n# -year:    2011-01-01 - 2011-03-31\\n# -domain:  news\\n# -sources(left):    New York Times (NYT) 637, Washington Post (WP) 508\\n#         (center):  National Public Radio (NPR) 109, Reuters (RET) 300\\n#         (right):   FoxNews (FN) 2735, Newsmax (NM) 180\\n\\n# directory path of relation models\\nRELATION_MODELS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/models/fourthTry\\\"\\n\\n# model names\\nRELATION_MODELS = [\\n    \\\"RM_2011_news_NYT.sqlite\\\",\\n    \\\"RM_2011_news_WP.sqlite\\\",\\n    \\\"RM_2011_news_NPR.sqlite\\\",\\n    \\\"RM_2011_news_RET.sqlite\\\",\\n    \\\"RM_2011_news_FN.sqlite\\\",\\n    \\\"RM_2011_news_NM.sqlite\\\",\\n]\\n#\";\n",
       "                var nbb_formatted_code = \"# Fourth try\\n# two models from newssources with different biases each, for comparing slant coherence within\\n# different directions. Timeslots with gapless news reporting were chosen.\\n#\\n# -year:    2011-01-01 - 2011-03-31\\n# -domain:  news\\n# -sources(left):    New York Times (NYT) 637, Washington Post (WP) 508\\n#         (center):  National Public Radio (NPR) 109, Reuters (RET) 300\\n#         (right):   FoxNews (FN) 2735, Newsmax (NM) 180\\n\\n# directory path of relation models\\nRELATION_MODELS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/models/fourthTry\\\"\\n\\n# model names\\nRELATION_MODELS = [\\n    \\\"RM_2011_news_NYT.sqlite\\\",\\n    \\\"RM_2011_news_WP.sqlite\\\",\\n    \\\"RM_2011_news_NPR.sqlite\\\",\\n    \\\"RM_2011_news_RET.sqlite\\\",\\n    \\\"RM_2011_news_FN.sqlite\\\",\\n    \\\"RM_2011_news_NM.sqlite\\\",\\n]\\n#\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fourth try\n",
    "# two models from newssources with different biases each, for comparing slant coherence within\n",
    "# different directions. Timeslots with gapless news reporting were chosen.\n",
    "#\n",
    "# -year:    2011-01-01 - 2011-03-31\n",
    "# -domain:  news\n",
    "# -sources(left):    New York Times (NYT) 637, Washington Post (WP) 508\n",
    "#         (center):  National Public Radio (NPR) 109, Reuters (RET) 300\n",
    "#         (right):   FoxNews (FN) 2735, Newsmax (NM) 180\n",
    "\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/fourthTry\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2011_news_NYT.sqlite\",\n",
    "    \"RM_2011_news_WP.sqlite\",\n",
    "    \"RM_2011_news_NPR.sqlite\",\n",
    "    \"RM_2011_news_RET.sqlite\",\n",
    "    \"RM_2011_news_FN.sqlite\",\n",
    "    \"RM_2011_news_NM.sqlite\",\n",
    "]\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# number of entities you want to compare\\nNO_ENTITIES = 10\\n\\n# reference entity\\nTOPIC_OF_INTEREST = \\\"obama\\\"\\n\\n# reference entity list\\nTOPIC_OF_INTEREST_LIST2 = [\\n    \\\"united_states\\\",\\n    \\\"germany\\\",\\n    \\\"russia\\\",\\n    \\\"india\\\",\\n    \\\"china\\\",\\n]\\n\\n# co-occurrence entity list\\nTOPIC_OF_INTEREST_LIST = [\\n    \\\"united_states\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"# number of entities you want to compare\\nNO_ENTITIES = 10\\n\\n# reference entity\\nTOPIC_OF_INTEREST = \\\"obama\\\"\\n\\n# reference entity list\\nTOPIC_OF_INTEREST_LIST2 = [\\n    \\\"united_states\\\",\\n    \\\"germany\\\",\\n    \\\"russia\\\",\\n    \\\"india\\\",\\n    \\\"china\\\",\\n]\\n\\n# co-occurrence entity list\\nTOPIC_OF_INTEREST_LIST = [\\n    \\\"united_states\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of entities you want to compare\n",
    "NO_ENTITIES = 10\n",
    "\n",
    "# reference entity\n",
    "TOPIC_OF_INTEREST = \"obama\"\n",
    "\n",
    "# reference entity list\n",
    "TOPIC_OF_INTEREST_LIST2 = [\n",
    "    \"united_states\",\n",
    "    \"germany\",\n",
    "    \"russia\",\n",
    "    \"india\",\n",
    "    \"china\",\n",
    "]\n",
    "\n",
    "# co-occurrence entity list\n",
    "TOPIC_OF_INTEREST_LIST = [\n",
    "    \"united_states\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-square contributions:\n",
      "                         washington  united_states   white_house  congress  \\\n",
      "RM_2011_news_NYT.sqlite         0.0            0.0  1.364516e-30       0.0   \n",
      "\n",
      "                         libya  america  senate  muammar_el-qaddafi  qaddafi  \\\n",
      "RM_2011_news_NYT.sqlite    0.0      0.0     0.0                 0.0      0.0   \n",
      "\n",
      "                         house  \n",
      "RM_2011_news_NYT.sqlite    0.0  \n",
      "\n",
      "Results:\n",
      "nan\n",
      "1.3645161603822908e-30\n",
      "['RM_2011_news_NYT.sqlite', 'RM_2011_news_NYT.sqlite']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/lib/python3.7/site-packages/statsmodels/stats/contingency_tables.py:252: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = (statistic - e_stat) / sd_stat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chi-square contributions:\n",
      "                         washington  united_states  white_house  congress  \\\n",
      "RM_2011_news_NYT.sqlite    0.002075       0.028772     0.677703  0.454102   \n",
      "RM_2011_news_WP.sqlite     0.002275       0.031539     0.742867  0.497765   \n",
      "\n",
      "                            libya  america    senate  muammar_el-qaddafi  \\\n",
      "RM_2011_news_NYT.sqlite  0.188867  0.00083  0.175765            7.165066   \n",
      "RM_2011_news_WP.sqlite   0.207027  0.00091  0.192665            7.854014   \n",
      "\n",
      "                          qaddafi     house  \n",
      "RM_2011_news_NYT.sqlite  6.731326  1.619109  \n",
      "RM_2011_news_WP.sqlite   7.378569  1.774792  \n",
      "\n",
      "Results:\n",
      "4.433836065464991e-05\n",
      "35.72603720959802\n",
      "['RM_2011_news_NYT.sqlite', 'RM_2011_news_WP.sqlite']\n",
      "\n",
      "Chi-square contributions:\n",
      "                         washington  united_states  white_house  congress  \\\n",
      "RM_2011_news_NYT.sqlite    0.011772       0.109773     0.370634  0.021865   \n",
      "RM_2011_news_NPR.sqlite    0.059382       0.553724     1.869569  0.110292   \n",
      "\n",
      "                            libya   america    senate  muammar_el-qaddafi  \\\n",
      "RM_2011_news_NYT.sqlite  0.617558  0.284730  0.052894            0.424729   \n",
      "RM_2011_news_NPR.sqlite  3.115117  1.436248  0.266809            2.142440   \n",
      "\n",
      "                          qaddafi     house  \n",
      "RM_2011_news_NYT.sqlite  0.392856  0.531724  \n",
      "RM_2011_news_NPR.sqlite  1.981661  2.682147  \n",
      "\n",
      "Results:\n",
      "0.048156390780631386\n",
      "17.035922854558393\n",
      "['RM_2011_news_NYT.sqlite', 'RM_2011_news_NPR.sqlite']\n",
      "\n",
      "Chi-square contributions:\n",
      "                         washington  united_states  white_house  congress  \\\n",
      "RM_2011_news_NYT.sqlite    1.828188       0.054825     0.818074  0.141381   \n",
      "RM_2011_news_RET.sqlite    4.341947       0.130208     1.942927  0.335779   \n",
      "\n",
      "                            libya   america  senate  muammar_el-qaddafi  \\\n",
      "RM_2011_news_NYT.sqlite  2.333645  0.329435     0.0            1.906143   \n",
      "RM_2011_news_RET.sqlite  5.542407  0.782407     0.0            4.527090   \n",
      "\n",
      "                          qaddafi     house  \n",
      "RM_2011_news_NYT.sqlite  1.782484  0.263548  \n",
      "RM_2011_news_RET.sqlite  4.233399  0.625926  \n",
      "\n",
      "Results:\n",
      "0.00020558448161245302\n",
      "31.91981273168585\n",
      "['RM_2011_news_NYT.sqlite', 'RM_2011_news_RET.sqlite']\n"
     ]
    }
   ],
   "source": [
    "# extracting a contingency table from a single reference entity\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "\n",
    "for i in range(len(RELATION_MODELS)):\n",
    "    for j in range(len(RELATION_MODELS)):\n",
    "        relation_models = []\n",
    "        relation_models = [RELATION_MODELS[i]] + [RELATION_MODELS[j]]\n",
    "\n",
    "        contingency_table = build_contingency_table_from_single_topic(\n",
    "            RELATION_MODELS_PATH, relation_models, TOPIC_OF_INTEREST, NO_ENTITIES\n",
    "        )\n",
    "\n",
    "        chi_squared(contingency_table, False, False, True)\n",
    "        print(relation_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "df          45\n",
      "pvalue      0.0\n",
      "statistic   254.06312702634767\n",
      "254.06312702634767\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"contingency_table = build_contingency_table_from_single_topic(\\n    RELATION_MODELS_PATH, RELATION_MODELS, TOPIC_OF_INTEREST, NO_ENTITIES\\n)\\n\\nchi_squared(contingency_table)\";\n",
       "                var nbb_formatted_code = \"contingency_table = build_contingency_table_from_single_topic(\\n    RELATION_MODELS_PATH, RELATION_MODELS, TOPIC_OF_INTEREST, NO_ENTITIES\\n)\\n\\nchi_squared(contingency_table)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contingency_table = build_contingency_table_from_single_topic(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS, TOPIC_OF_INTEREST, NO_ENTITIES\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test coherence of cooccurrences within same slant group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# liberal\n",
    "\n",
    "contingency_table = build_contingency_table_from_single_topic(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS[:2], TOPIC_OF_INTEREST, NO_ENTITIES,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table, True, False, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center\n",
    "\n",
    "contingency_table = build_contingency_table_from_single_topic(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS[2:4], TOPIC_OF_INTEREST, NO_ENTITIES,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table, True, False, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative\n",
    "\n",
    "contingency_table = build_contingency_table_from_single_topic(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS[4:], TOPIC_OF_INTEREST, NO_ENTITIES,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table, True, False, True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liberal\n",
    "\n",
    "contingency_table = compare_entity_lists(\n",
    "    RELATION_MODELS_PATH,\n",
    "    RELATION_MODELS[:2],\n",
    "    TOPIC_OF_INTEREST_LIST,\n",
    "    TOPIC_OF_INTEREST_LIST2,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center\n",
    "contingency_table = compare_entity_lists(\n",
    "    RELATION_MODELS_PATH,\n",
    "    RELATION_MODELS[2:4],\n",
    "    TOPIC_OF_INTEREST_LIST,\n",
    "    TOPIC_OF_INTEREST_LIST2,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative\n",
    "contingency_table = compare_entity_lists(\n",
    "    RELATION_MODELS_PATH,\n",
    "    RELATION_MODELS[4:],\n",
    "    TOPIC_OF_INTEREST_LIST,\n",
    "    TOPIC_OF_INTEREST_LIST2,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table, True, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a contingency table from a list of reference entities \n",
    "contingency_table = build_contingency_table_from_topic_list(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS, TOPIC_OF_INTEREST_LIST, NO_ENTITIES)\n",
    "\n",
    "chi_squared(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a contingency table from two lists of entities\n",
    "\n",
    "contingency_table = compare_entity_lists(\n",
    "    RELATION_MODELS_PATH,\n",
    "    RELATION_MODELS,\n",
    "    TOPIC_OF_INTEREST_LIST,\n",
    "    TOPIC_OF_INTEREST_LIST2,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # initialize DistanceMeasure with reference-model\n",
    "dm = DistanceMeasure(RELATION_MODELS_PATH, str(RELATION_MODELS[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "topNYT = dm.get_top_co_occurrences(\n",
    "    TOPIC_OF_INTEREST, cutoff=10, e1_is_synset=0, e2_is_synset=0\n",
    ")\n",
    "\n",
    "dm = DistanceMeasure(RELATION_MODELS_PATH, str(RELATION_MODELS[1]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "topFN = dm.get_top_co_occurrences(\n",
    "    TOPIC_OF_INTEREST, cutoff=10, e1_is_synset=0, e2_is_synset=0\n",
    ")\n",
    "\n",
    "\n",
    "print(topNYT)\n",
    "print(topFN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
