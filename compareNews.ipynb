{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master Thesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook can be understood as a walkthrough through the experiments I ran for my master thesis.\n",
    "To keep it somewhat clear I pushed large functions beyond the imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Imports & functions](#imports&functions)\n",
    "### 2. [Tryout-datasets](#datasets)\n",
    "### 3. [Final datasets](#finalDatasets)\n",
    "### 4. [Parameter tuning](#parameterTuning)\n",
    "#### 4.1 [n - entity estimation](#nEntity)\n",
    "#### 4.2 [reference entity estimation](#refEntity)\n",
    "### 5. [Hypothesis testing](#hypothesisTesting)\n",
    "#### 5.1 [Hypothesis 1](#hyp1)\n",
    "#### 5.2 [Hypothesis 2](#hyp2)\n",
    "#### 5.3 [Hypothesis 3](#hyp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions <a class=\"anchor\" id=\"imports&functions\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# for pretty code\\n%load_ext nb_black\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"# for pretty code\\n%load_ext nb_black\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for pretty code\n",
    "%load_ext nb_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /home/jonas/anaconda3/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jonas/anaconda3/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jonas/anaconda3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\nimport statsmodels.api as sm\\nimport matplotlib.pyplot as plt\\nimport multiprocessing as mp\\nimport nltk.data\\nimport statistics\\nimport networkx as nx\\nimport math\\nimport warnings\\nimport pyLDAvis\\nimport pyLDAvis.gensim\\n\\nfrom tqdm import tqdm_notebook, tnrange, tqdm\\nfrom matplotlib.pyplot import figure\\nfrom newsrelations.query_db.relation_query import DBQueryHandlerCoocc\\nfrom newsrelations.helper_classes.synonym_handler import SynonymHandler\\nfrom newsrelations.metrics.distances import DistanceMeasure\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\nfrom gensim import models, corpora, similarities\\n\\nnltk.download(\\\"brown\\\")\\nnltk.download(\\\"vader_lexicon\\\")\\nnltk.download(\\\"stopwords\\\")\\ntokenizer = nltk.data.load(\\n    \\\"/home/jonas/anaconda3/lib/python3.7/nltk_data/punkt/english.pickle\\\"\\n)\\n\\nstop_words = set(stopwords.words(\\\"english\\\"))\\n# extend stopwords with typical stopwords from news-paper articles\\nextend_stopwords = [\\n    \\\"also\\\",\\n    \\\"said\\\",\\n    \\\"one\\\",\\n    \\\"new\\\",\\n    \\\"two\\\",\\n    \\\"says\\\",\\n    \\\"could\\\",\\n    \\\"would\\\",\\n    \\\"should\\\",\\n    \\\"three\\\",\\n    \\\"three\\\",\\n    \\\"like\\\",\\n]\\nfor word in extend_stopwords:\\n    stop_words.add(word)\\n\\n\\npyLDAvis.enable_notebook()\\nwarnings.filterwarnings(\\\"ignore\\\")\\npd.set_option(\\\"display.max_rows\\\", None)\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport statsmodels.api as sm\\nimport matplotlib.pyplot as plt\\nimport multiprocessing as mp\\nimport nltk.data\\nimport statistics\\nimport networkx as nx\\nimport math\\nimport warnings\\nimport pyLDAvis\\nimport pyLDAvis.gensim\\n\\nfrom tqdm import tqdm_notebook, tnrange, tqdm\\nfrom matplotlib.pyplot import figure\\nfrom newsrelations.query_db.relation_query import DBQueryHandlerCoocc\\nfrom newsrelations.helper_classes.synonym_handler import SynonymHandler\\nfrom newsrelations.metrics.distances import DistanceMeasure\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\\nfrom nltk.corpus import stopwords\\nfrom nltk.tokenize import word_tokenize\\nfrom gensim import models, corpora, similarities\\n\\nnltk.download(\\\"brown\\\")\\nnltk.download(\\\"vader_lexicon\\\")\\nnltk.download(\\\"stopwords\\\")\\ntokenizer = nltk.data.load(\\n    \\\"/home/jonas/anaconda3/lib/python3.7/nltk_data/punkt/english.pickle\\\"\\n)\\n\\nstop_words = set(stopwords.words(\\\"english\\\"))\\n# extend stopwords with typical stopwords from news-paper articles\\nextend_stopwords = [\\n    \\\"also\\\",\\n    \\\"said\\\",\\n    \\\"one\\\",\\n    \\\"new\\\",\\n    \\\"two\\\",\\n    \\\"says\\\",\\n    \\\"could\\\",\\n    \\\"would\\\",\\n    \\\"should\\\",\\n    \\\"three\\\",\\n    \\\"three\\\",\\n    \\\"like\\\",\\n]\\nfor word in extend_stopwords:\\n    stop_words.add(word)\\n\\n\\npyLDAvis.enable_notebook()\\nwarnings.filterwarnings(\\\"ignore\\\")\\npd.set_option(\\\"display.max_rows\\\", None)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import nltk.data\n",
    "import statistics\n",
    "import networkx as nx\n",
    "import math\n",
    "import warnings\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange, tqdm\n",
    "from matplotlib.pyplot import figure\n",
    "from newsrelations.query_db.relation_query import DBQueryHandlerCoocc\n",
    "from newsrelations.helper_classes.synonym_handler import SynonymHandler\n",
    "from newsrelations.metrics.distances import DistanceMeasure\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import models, corpora, similarities\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download(\"stopwords\")\n",
    "tokenizer = nltk.data.load(\n",
    "    \"/home/jonas/anaconda3/lib/python3.7/nltk_data/punkt/english.pickle\"\n",
    ")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# extend stopwords with typical stopwords from news-paper articles\n",
    "extend_stopwords = [\n",
    "    \"also\",\n",
    "    \"said\",\n",
    "    \"one\",\n",
    "    \"new\",\n",
    "    \"two\",\n",
    "    \"says\",\n",
    "    \"could\",\n",
    "    \"would\",\n",
    "    \"should\",\n",
    "    \"three\",\n",
    "    \"three\",\n",
    "    \"like\",\n",
    "]\n",
    "for word in extend_stopwords:\n",
    "    stop_words.add(word)\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def build_contingency_table_from_single_topic(\\n    relation_models_path, relation_models, topic_of_interest, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic [TOPIC_OF_INTEREST].\\n    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\\n    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest = str           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    E1_SYNSET = 0\\n    E2_SYNSET = 1\\n\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest,\\n        cutoff=no_entities,\\n        e1_is_synset=E1_SYNSET,\\n        e2_is_synset=E2_SYNSET,\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(relation_models[0])],\\n    )\\n\\n    # loop through all remaining models\\n    for model in relation_models[1:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        # buffer for cooccurrences\\n        co_occs = []\\n        # loop through all entities and get number of co-occurrences\\n        for row in contingency_table.index:\\n            co_occs.append(\\n                len(\\n                    list(\\n                        db_handler.select_relations(\\n                            e1=topic_of_interest.lower(),\\n                            e2=row.lower(),\\n                            e1_is_synset=E1_SYNSET,\\n                            e2_is_synset=E2_SYNSET,\\n                        )\\n                    )\\n                )\\n            )\\n\\n        contingency_table[str(model)] = co_occs\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def build_contingency_table_from_single_topic(\\n    relation_models_path, relation_models, topic_of_interest, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic [TOPIC_OF_INTEREST].\\n    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\\n    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest = str           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    E1_SYNSET = 0\\n    E2_SYNSET = 1\\n\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest,\\n        cutoff=no_entities,\\n        e1_is_synset=E1_SYNSET,\\n        e2_is_synset=E2_SYNSET,\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(relation_models[0])],\\n    )\\n\\n    # loop through all remaining models\\n    for model in relation_models[1:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        # buffer for cooccurrences\\n        co_occs = []\\n        # loop through all entities and get number of co-occurrences\\n        for row in contingency_table.index:\\n            co_occs.append(\\n                len(\\n                    list(\\n                        db_handler.select_relations(\\n                            e1=topic_of_interest.lower(),\\n                            e2=row.lower(),\\n                            e1_is_synset=E1_SYNSET,\\n                            e2_is_synset=E2_SYNSET,\\n                        )\\n                    )\\n                )\\n            )\\n\\n        contingency_table[str(model)] = co_occs\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_contingency_table_from_single_topic(\n",
    "    relation_models_path, relation_models, topic_of_interest, no_entities=10\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined topic [TOPIC_OF_INTEREST].\n",
    "    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_of_interest = str           \n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    E1_SYNSET = 0\n",
    "    E2_SYNSET = 1\n",
    "\n",
    "    # initialize DistanceMeasure with reference-model\n",
    "    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest,\n",
    "        cutoff=no_entities,\n",
    "        e1_is_synset=E1_SYNSET,\n",
    "        e2_is_synset=E2_SYNSET,\n",
    "    )\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(\n",
    "        np.array([t[1] for t in top]),\n",
    "        index=[t[0] for t in top],\n",
    "        columns=[str(relation_models[0])],\n",
    "    )\n",
    "\n",
    "    # loop through all remaining models\n",
    "    for model in relation_models[1:]:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        # buffer for cooccurrences\n",
    "        co_occs = []\n",
    "        # loop through all entities and get number of co-occurrences\n",
    "        for row in contingency_table.index:\n",
    "            co_occs.append(\n",
    "                len(\n",
    "                    list(\n",
    "                        db_handler.select_relations(\n",
    "                            e1=topic_of_interest.lower(),\n",
    "                            e2=row.lower(),\n",
    "                            e1_is_synset=E1_SYNSET,\n",
    "                            e2_is_synset=E2_SYNSET,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        contingency_table[str(model)] = co_occs\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def build_contingency_table_from_preset_cooccurrences(\\n    relation_models_path, model, cooccurrences_list\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined co_occurrences [co_occurrences_list].\\n    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\\n    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            co_occurrences_list = list of tuples\\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    E1_SYNSET = 0\\n    E2_SYNSET = 0\\n\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(columns=[str(model)])\\n\\n    # initialize db_handler()\\n    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n    # buffer for cooccurrences\\n    co_occs = []\\n    # loop through all entities and get number of co-occurrences\\n    for single_tuple in cooccurrences_list:\\n        co_occs.append(\\n            len(\\n                list(\\n                    db_handler.select_relations(\\n                        e1=single_tuple[0].lower(),\\n                        e2=single_tuple[1].lower(),\\n                        e1_is_synset=E1_SYNSET,\\n                        e2_is_synset=E2_SYNSET,\\n                    )\\n                )\\n            )\\n        )\\n\\n    contingency_table[str(model)] = co_occs\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def build_contingency_table_from_preset_cooccurrences(\\n    relation_models_path, model, cooccurrences_list\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined co_occurrences [co_occurrences_list].\\n    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\\n    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            co_occurrences_list = list of tuples\\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    E1_SYNSET = 0\\n    E2_SYNSET = 0\\n\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(columns=[str(model)])\\n\\n    # initialize db_handler()\\n    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n    # buffer for cooccurrences\\n    co_occs = []\\n    # loop through all entities and get number of co-occurrences\\n    for single_tuple in cooccurrences_list:\\n        co_occs.append(\\n            len(\\n                list(\\n                    db_handler.select_relations(\\n                        e1=single_tuple[0].lower(),\\n                        e2=single_tuple[1].lower(),\\n                        e1_is_synset=E1_SYNSET,\\n                        e2_is_synset=E2_SYNSET,\\n                    )\\n                )\\n            )\\n        )\\n\\n    contingency_table[str(model)] = co_occs\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_contingency_table_from_preset_cooccurrences(\n",
    "    relation_models_path, model, cooccurrences_list\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined co_occurrences [co_occurrences_list].\n",
    "    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            co_occurrences_list = list of tuples\n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    E1_SYNSET = 0\n",
    "    E2_SYNSET = 0\n",
    "\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(columns=[str(model)])\n",
    "\n",
    "    # initialize db_handler()\n",
    "    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "    # buffer for cooccurrences\n",
    "    co_occs = []\n",
    "    # loop through all entities and get number of co-occurrences\n",
    "    for single_tuple in cooccurrences_list:\n",
    "        co_occs.append(\n",
    "            len(\n",
    "                list(\n",
    "                    db_handler.select_relations(\n",
    "                        e1=single_tuple[0].lower(),\n",
    "                        e2=single_tuple[1].lower(),\n",
    "                        e1_is_synset=E1_SYNSET,\n",
    "                        e2_is_synset=E2_SYNSET,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    contingency_table[str(model)] = co_occs\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def explain_models(relation_models):\\n    \\\"\\\"\\\"\\n    This function lists the models from the relation_models list and their counter index\\n    \\n    Input: relation_models = list\\n    \\n    Output: None\\n    \\\"\\\"\\\"\\n    i = 0\\n    for model in relation_models:\\n        print(\\\"model(\\\" + str(i) + \\\"): \\\" + str(model))\\n        i += 1\\n    return\";\n",
       "                var nbb_formatted_code = \"def explain_models(relation_models):\\n    \\\"\\\"\\\"\\n    This function lists the models from the relation_models list and their counter index\\n    \\n    Input: relation_models = list\\n    \\n    Output: None\\n    \\\"\\\"\\\"\\n    i = 0\\n    for model in relation_models:\\n        print(\\\"model(\\\" + str(i) + \\\"): \\\" + str(model))\\n        i += 1\\n    return\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explain_models(relation_models):\n",
    "    \"\"\"\n",
    "    This function lists the models from the relation_models list and their counter index\n",
    "    \n",
    "    Input: relation_models = list\n",
    "    \n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for model in relation_models:\n",
    "        print(\"model(\" + str(i) + \"): \" + str(model))\n",
    "        i += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def build_contingency_table_from_topic_list(\\n    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic list [topic_of_interest_list].\\n    The first model in [relation_models] is the reference model all other models will be compared with.\\n    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \\n    model and builds a contingency table.\\n    \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest_list = list           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # identifier for models in relation_models_list\\n    i = 0\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(topic_of_interest_list[0]) + \\\" (\\\" + str(i) + \\\")\\\"],\\n    )\\n\\n    # loop through the models\\n    for model in relation_models[:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic in topic_of_interest_list:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for row in contingency_table.index:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic.lower(),\\n                                e2=row.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def build_contingency_table_from_topic_list(\\n    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\\n):\\n    \\\"\\\"\\\"\\n    This function builds a contingency table from a input list of relation models generated with relation_miner.py \\n    in regards to predetermined topic list [topic_of_interest_list].\\n    The first model in [relation_models] is the reference model all other models will be compared with.\\n    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \\n    model and builds a contingency table.\\n    \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_of_interest_list = list           \\n            no_entities = int (standard 10)\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # identifier for models in relation_models_list\\n    i = 0\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize DistanceMeasure with reference-model\\n    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\\n\\n    # extract top NO_ENTITIES entities\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\\n    )\\n    # write first row of contingency_table\\n    contingency_table = pd.DataFrame(\\n        np.array([t[1] for t in top]),\\n        index=[t[0] for t in top],\\n        columns=[str(topic_of_interest_list[0]) + \\\" (\\\" + str(i) + \\\")\\\"],\\n    )\\n\\n    # loop through the models\\n    for model in relation_models[:]:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic in topic_of_interest_list:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for row in contingency_table.index:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic.lower(),\\n                                e2=row.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_contingency_table_from_topic_list(\n",
    "    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined topic list [topic_of_interest_list].\n",
    "    The first model in [relation_models] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \n",
    "    model and builds a contingency table.\n",
    "    \n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_of_interest_list = list           \n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # identifier for models in relation_models_list\n",
    "    i = 0\n",
    "    # print models with idx\n",
    "    explain_models(relation_models)\n",
    "\n",
    "    # initialize DistanceMeasure with reference-model\n",
    "    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\n",
    "    )\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(\n",
    "        np.array([t[1] for t in top]),\n",
    "        index=[t[0] for t in top],\n",
    "        columns=[str(topic_of_interest_list[0]) + \" (\" + str(i) + \")\"],\n",
    "    )\n",
    "\n",
    "    # loop through the models\n",
    "    for model in relation_models[:]:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        for topic in topic_of_interest_list:\n",
    "            # buffer for co-occurrencces\n",
    "            co_occs = []\n",
    "\n",
    "            # loop through all all entities and get number of co-occurrences\n",
    "            for row in contingency_table.index:\n",
    "                co_occs.append(\n",
    "                    len(\n",
    "                        list(\n",
    "                            db_handler.select_relations(\n",
    "                                e1=topic.lower(),\n",
    "                                e2=row.lower(),\n",
    "                                e1_is_synset=0,\n",
    "                                e2_is_synset=0,\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            contingency_table[str(topic) + \" (\" + str(i) + \")\"] = co_occs\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def compare_entity_lists(\\n    relation_models_path, relation_models, topic_list1, topic_list2\\n):\\n    \\\"\\\"\\\"\\n    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\\n    from a list of relation models \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_list1 = list           \\n            topic_list2 = list\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # idx for models\\n    i = 0\\n\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize contingency_table\\n    contingency_table = pd.DataFrame(index=topic_list2)\\n\\n    # loop through the models\\n    for model in relation_models:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic1 in topic_list1:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for topic2 in topic_list2:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic1.lower(),\\n                                e2=topic2.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic1) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_formatted_code = \"def compare_entity_lists(\\n    relation_models_path, relation_models, topic_list1, topic_list2\\n):\\n    \\\"\\\"\\\"\\n    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\\n    from a list of relation models \\n    \\n    input:  relation_models = list\\n            relation_models_path = str \\n            topic_list1 = list           \\n            topic_list2 = list\\n            \\n    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\\n    \\\"\\\"\\\"\\n    # idx for models\\n    i = 0\\n\\n    # print models with idx\\n    explain_models(relation_models)\\n\\n    # initialize contingency_table\\n    contingency_table = pd.DataFrame(index=topic_list2)\\n\\n    # loop through the models\\n    for model in relation_models:\\n        # initialize db_handler()\\n        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n\\n        for topic1 in topic_list1:\\n            # buffer for co-occurrencces\\n            co_occs = []\\n\\n            # loop through all all entities and get number of co-occurrences\\n            for topic2 in topic_list2:\\n                co_occs.append(\\n                    len(\\n                        list(\\n                            db_handler.select_relations(\\n                                e1=topic1.lower(),\\n                                e2=topic2.lower(),\\n                                e1_is_synset=0,\\n                                e2_is_synset=0,\\n                            )\\n                        )\\n                    )\\n                )\\n            contingency_table[str(topic1) + \\\" (\\\" + str(i) + \\\")\\\"] = co_occs\\n\\n        i += 1\\n\\n    # transpose the contingency table to get it into the right format\\n    contingency_table = contingency_table.transpose()\\n\\n    return contingency_table\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_entity_lists(\n",
    "    relation_models_path, relation_models, topic_list1, topic_list2\n",
    "):\n",
    "    \"\"\"\n",
    "    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\n",
    "    from a list of relation models \n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_list1 = list           \n",
    "            topic_list2 = list\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # idx for models\n",
    "    i = 0\n",
    "\n",
    "    # print models with idx\n",
    "    explain_models(relation_models)\n",
    "\n",
    "    # initialize contingency_table\n",
    "    contingency_table = pd.DataFrame(index=topic_list2)\n",
    "\n",
    "    # loop through the models\n",
    "    for model in relation_models:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        for topic1 in topic_list1:\n",
    "            # buffer for co-occurrencces\n",
    "            co_occs = []\n",
    "\n",
    "            # loop through all all entities and get number of co-occurrences\n",
    "            for topic2 in topic_list2:\n",
    "                co_occs.append(\n",
    "                    len(\n",
    "                        list(\n",
    "                            db_handler.select_relations(\n",
    "                                e1=topic1.lower(),\n",
    "                                e2=topic2.lower(),\n",
    "                                e1_is_synset=0,\n",
    "                                e2_is_synset=0,\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            contingency_table[str(topic1) + \" (\" + str(i) + \")\"] = co_occs\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"def create_tf_idf_table(relation_models_path, model):\\n    \\\"\\\"\\\"\\n    This function calculates the TF-IDF value over all words mentioned in the [model]s corpus.\\n    \\n    input:      relation_models_path = string\\n                realtion_model = string\\n    \\n    output:     df = DataFrame (containing all tf-idf-values for each word)\\n    \\\"\\\"\\\"\\n    # number of top words in corpus\\n    N = 10\\n    \\n    # initialize db_handler\\n    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n    # retrieve all articles from database into article\\n    articles = db_handler.get_articles()\\n\\n\\n    preprocessed_articles = \\\"\\\"\\n\\n    # preprocessing of articles\\n    for article in tqdm(articles):\\n        # get text, lower it and tokenize it into sentences, strip punctuation and stop words\\n        single_article = str(article.text)\\n        single_article = single_article.lower()\\n        single_article = word_tokenize(single_article)\\n        single_article = [word for word in single_article if word.isalnum()]\\n        single_article = [word for word in single_article if not word in stop_words]\\n\\n        # concat everything into a string again \\n        art = \\\"\\\"\\n        for word in single_article:\\n            art = art + \\\" \\\" + word\\n        # append to corpus-string   \\n        preprocessed_articles = preprocessed_articles + \\\" \\\" + art    \\n    preprocessed_articles = [preprocessed_articles]\\n    \\n    # calculate TF-IDF\\n    vectorizer = TfidfVectorizer()\\n    vectors = vectorizer.fit_transform(preprocessed_articles)\\n    names = vectorizer.get_feature_names()\\n    data = vectors.todense().tolist()\\n\\n    # Create a dataframe with the results\\n    df = pd.DataFrame(data, columns=names)\\n    df = df[filter(lambda x: x not in list(stop_words) , df.columns)]\\n    \\\"\\\"\\\"\\n    df\\n\\n    for i in df.iterrows():\\n        print(i[1].sort_values(ascending=False)[:N])\\n    \\\"\\\"\\\"    \\n    return df\";\n",
       "                var nbb_formatted_code = \"def create_tf_idf_table(relation_models_path, model):\\n    \\\"\\\"\\\"\\n    This function calculates the TF-IDF value over all words mentioned in the [model]s corpus.\\n    \\n    input:      relation_models_path = string\\n                realtion_model = string\\n    \\n    output:     df = DataFrame (containing all tf-idf-values for each word)\\n    \\\"\\\"\\\"\\n    # number of top words in corpus\\n    N = 10\\n\\n    # initialize db_handler\\n    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n    # retrieve all articles from database into article\\n    articles = db_handler.get_articles()\\n\\n    preprocessed_articles = \\\"\\\"\\n\\n    # preprocessing of articles\\n    for article in tqdm(articles):\\n        # get text, lower it and tokenize it into sentences, strip punctuation and stop words\\n        single_article = str(article.text)\\n        single_article = single_article.lower()\\n        single_article = word_tokenize(single_article)\\n        single_article = [word for word in single_article if word.isalnum()]\\n        single_article = [word for word in single_article if not word in stop_words]\\n\\n        # concat everything into a string again\\n        art = \\\"\\\"\\n        for word in single_article:\\n            art = art + \\\" \\\" + word\\n        # append to corpus-string\\n        preprocessed_articles = preprocessed_articles + \\\" \\\" + art\\n    preprocessed_articles = [preprocessed_articles]\\n\\n    # calculate TF-IDF\\n    vectorizer = TfidfVectorizer()\\n    vectors = vectorizer.fit_transform(preprocessed_articles)\\n    names = vectorizer.get_feature_names()\\n    data = vectors.todense().tolist()\\n\\n    # Create a dataframe with the results\\n    df = pd.DataFrame(data, columns=names)\\n    df = df[filter(lambda x: x not in list(stop_words), df.columns)]\\n    \\\"\\\"\\\"\\n    df\\n\\n    for i in df.iterrows():\\n        print(i[1].sort_values(ascending=False)[:N])\\n    \\\"\\\"\\\"\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tf_idf_table(relation_models_path, model):\n",
    "    \"\"\"\n",
    "    This function calculates the TF-IDF value over all words mentioned in the [model]s corpus.\n",
    "    \n",
    "    input:      relation_models_path = string\n",
    "                realtion_model = string\n",
    "    \n",
    "    output:     df = DataFrame (containing all tf-idf-values for each word)\n",
    "    \"\"\"\n",
    "    # number of top words in corpus\n",
    "    N = 10\n",
    "    \n",
    "    # initialize db_handler\n",
    "    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "    # retrieve all articles from database into article\n",
    "    articles = db_handler.get_articles()\n",
    "\n",
    "\n",
    "    preprocessed_articles = \"\"\n",
    "\n",
    "    # preprocessing of articles\n",
    "    for article in tqdm(articles):\n",
    "        # get text, lower it and tokenize it into sentences, strip punctuation and stop words\n",
    "        single_article = str(article.text)\n",
    "        single_article = single_article.lower()\n",
    "        single_article = word_tokenize(single_article)\n",
    "        single_article = [word for word in single_article if word.isalnum()]\n",
    "        single_article = [word for word in single_article if not word in stop_words]\n",
    "\n",
    "        # concat everything into a string again \n",
    "        art = \"\"\n",
    "        for word in single_article:\n",
    "            art = art + \" \" + word\n",
    "        # append to corpus-string   \n",
    "        preprocessed_articles = preprocessed_articles + \" \" + art    \n",
    "    preprocessed_articles = [preprocessed_articles]\n",
    "    \n",
    "    # calculate TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(preprocessed_articles)\n",
    "    names = vectorizer.get_feature_names()\n",
    "    data = vectors.todense().tolist()\n",
    "\n",
    "    # Create a dataframe with the results\n",
    "    df = pd.DataFrame(data, columns=names)\n",
    "    df = df[filter(lambda x: x not in list(stop_words) , df.columns)]\n",
    "    \"\"\"\n",
    "    df\n",
    "\n",
    "    for i in df.iterrows():\n",
    "        print(i[1].sort_values(ascending=False)[:N])\n",
    "    \"\"\"    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"def LDA(relation_models_path, model):\\n    \\\"\\\"\\\"\\n    This function conducts a LDA on a given [model]\\n    \\n    input:     relation_models_path = str\\n               model = str\\n               \\n    output:    lda-model = model (for further use in LDAvis)\\n    \\\"\\\"\\\"\\n\\n    # initialize database handler\\n    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n    # retrieve all articles from database into article\\n    articles = db_handler.get_articles()\\n\\n    preprocessed_articles = []\\n    # preprocessing of articles\\n    for article in tqdm(articles):\\n        # get text, lower it and tokenize it into sentences, strip punctuation and stop words\\n        single_article = article.text\\n        single_article = single_article.lower()\\n        single_article = word_tokenize(single_article)\\n        single_article = [word for word in single_article if word.isalnum()]\\n        single_article = [word for word in single_article if not word in stop_words]\\n\\n        preprocessed_articles.append(single_article)\\n\\n    dictionary = corpora.Dictionary(preprocessed_articles)\\n\\n    # creating the corpus\\n    corpus = [dictionary.doc2bow(text) for text in preprocessed_articles]\\n\\n    # train the lda model on the corpus of all posts\\n    lda = models.LdaMulticore(corpus, id2word=dictionary, num_topics=5)\\n\\n    return lda, corpus, dictionary\";\n",
       "                var nbb_formatted_code = \"def LDA(relation_models_path, model):\\n    \\\"\\\"\\\"\\n    This function conducts a LDA on a given [model]\\n    \\n    input:     relation_models_path = str\\n               model = str\\n               \\n    output:    lda-model = model (for further use in LDAvis)\\n    \\\"\\\"\\\"\\n\\n    # initialize database handler\\n    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\\n    # retrieve all articles from database into article\\n    articles = db_handler.get_articles()\\n\\n    preprocessed_articles = []\\n    # preprocessing of articles\\n    for article in tqdm(articles):\\n        # get text, lower it and tokenize it into sentences, strip punctuation and stop words\\n        single_article = article.text\\n        single_article = single_article.lower()\\n        single_article = word_tokenize(single_article)\\n        single_article = [word for word in single_article if word.isalnum()]\\n        single_article = [word for word in single_article if not word in stop_words]\\n\\n        preprocessed_articles.append(single_article)\\n\\n    dictionary = corpora.Dictionary(preprocessed_articles)\\n\\n    # creating the corpus\\n    corpus = [dictionary.doc2bow(text) for text in preprocessed_articles]\\n\\n    # train the lda model on the corpus of all posts\\n    lda = models.LdaMulticore(corpus, id2word=dictionary, num_topics=5)\\n\\n    return lda, corpus, dictionary\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LDA(relation_models_path, model):\n",
    "    \"\"\"\n",
    "    This function conducts a LDA on a given [model]\n",
    "    \n",
    "    input:     relation_models_path = str\n",
    "               model = str\n",
    "               \n",
    "    output:    lda-model = model (for further use in LDAvis)\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize database handler\n",
    "    db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "    # retrieve all articles from database into article\n",
    "    articles = db_handler.get_articles()\n",
    "\n",
    "    preprocessed_articles = []\n",
    "    # preprocessing of articles\n",
    "    for article in tqdm(articles):\n",
    "        # get text, lower it and tokenize it into sentences, strip punctuation and stop words\n",
    "        single_article = article.text\n",
    "        single_article = single_article.lower()\n",
    "        single_article = word_tokenize(single_article)\n",
    "        single_article = [word for word in single_article if word.isalnum()]\n",
    "        single_article = [word for word in single_article if not word in stop_words]\n",
    "\n",
    "        preprocessed_articles.append(single_article)\n",
    "\n",
    "    dictionary = corpora.Dictionary(preprocessed_articles)\n",
    "\n",
    "    # creating the corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in preprocessed_articles]\n",
    "\n",
    "    # train the lda model on the corpus of all posts\n",
    "    lda = models.LdaMulticore(corpus, id2word=dictionary, num_topics=5)\n",
    "\n",
    "    return lda, corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"def chi_squared(contingency_table, print_orig = False, print_expect = False, print_chi_contr = False):\\n    \\\"\\\"\\\"\\n    This function conducts a chi-squared test of independence between the different rows of a contingency table\\n    \\n    input: contingency_table\\n    \\n    ouput: None\\n    \\\"\\\"\\\"\\n    contingency_table = sm.stats.Table(contingency_table)\\n    results = contingency_table.test_nominal_association()\\n    \\n    \\n    # orig contingency table\\n    if print_orig == True:\\n        print(\\\"Original contingency table:\\\")\\n        print(contingency_table.table_orig)\\n    # expected values\\n    if print_expect == True:\\n        print(\\\"\\\\nExpected values:\\\")\\n        print(contingency_table.fittedvalues)\\n    # chi-squared contributions\\n    if print_chi_contr == True:\\n        print(\\\"\\\\nChi-square contributions:\\\")\\n        print(contingency_table.chi2_contribs)\\n    \\n    # results\\n    print(\\\"\\\\nResults:\\\")\\n    print(results)\\n\\n   \\n    return\";\n",
       "                var nbb_formatted_code = \"def chi_squared(\\n    contingency_table, print_orig=False, print_expect=False, print_chi_contr=False\\n):\\n    \\\"\\\"\\\"\\n    This function conducts a chi-squared test of independence between the different rows of a contingency table\\n    \\n    input: contingency_table\\n    \\n    ouput: None\\n    \\\"\\\"\\\"\\n    contingency_table = sm.stats.Table(contingency_table)\\n    results = contingency_table.test_nominal_association()\\n\\n    # orig contingency table\\n    if print_orig == True:\\n        print(\\\"Original contingency table:\\\")\\n        print(contingency_table.table_orig)\\n    # expected values\\n    if print_expect == True:\\n        print(\\\"\\\\nExpected values:\\\")\\n        print(contingency_table.fittedvalues)\\n    # chi-squared contributions\\n    if print_chi_contr == True:\\n        print(\\\"\\\\nChi-square contributions:\\\")\\n        print(contingency_table.chi2_contribs)\\n\\n    # results\\n    print(\\\"\\\\nResults:\\\")\\n    print(results)\\n\\n    return\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chi_squared(contingency_table, print_orig = False, print_expect = False, print_chi_contr = False):\n",
    "    \"\"\"\n",
    "    This function conducts a chi-squared test of independence between the different rows of a contingency table\n",
    "    \n",
    "    input: contingency_table\n",
    "    \n",
    "    ouput: None\n",
    "    \"\"\"\n",
    "    contingency_table = sm.stats.Table(contingency_table)\n",
    "    results = contingency_table.test_nominal_association()\n",
    "    \n",
    "    \n",
    "    # orig contingency table\n",
    "    if print_orig == True:\n",
    "        print(\"Original contingency table:\")\n",
    "        print(contingency_table.table_orig)\n",
    "    # expected values\n",
    "    if print_expect == True:\n",
    "        print(\"\\nExpected values:\")\n",
    "        print(contingency_table.fittedvalues)\n",
    "    # chi-squared contributions\n",
    "    if print_chi_contr == True:\n",
    "        print(\"\\nChi-square contributions:\")\n",
    "        print(contingency_table.chi2_contribs)\n",
    "    \n",
    "    # results\n",
    "    print(\"\\nResults:\")\n",
    "    print(results)\n",
    "\n",
    "   \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"def do_chi_squared_comparison(\\n    relation_models_path, relation_models, topic_of_interest, no_entities\\n):\\n    \\\"\\\"\\\"\\n    This function extracts chi-squared test results for all combinations of news-outlets\\n    \\n    input: contingency_table\\n    \\n    ouput: None\\n    \\\"\\\"\\\"\\n\\n    # extracting a contingency table from a single reference entity\\n    i = 0\\n    j = 0\\n\\n    df_results = pd.DataFrame()\\n\\n    for i in range(len(relation_models)):\\n        for j in range(len(relation_models)):\\n            models = []\\n            models = [relation_models[i]] + [relation_models[j]]\\n\\n            contingency_table = build_contingency_table_from_single_topic(\\n                relation_models_path, models, topic_of_interest, no_entities\\n            )\\n\\n            contingency_table = sm.stats.Table(contingency_table)\\n            results = contingency_table.test_nominal_association()\\n\\n            df_results[\\n                str(relation_models[i][-10:-7])\\n                + \\\" - \\\"\\n                + str(relation_models[j][-10:-7])\\n            ] = [\\n                results.statistic,\\n                results.pvalue,\\n            ]\\n\\n    df_results = df_results.transpose()\\n    df_results = df_results.rename(columns={0: \\\"chi_sq\\\", 1: \\\"p_value\\\"})\\n    df_results\\n\\n    return df_results\";\n",
       "                var nbb_formatted_code = \"def do_chi_squared_comparison(\\n    relation_models_path, relation_models, topic_of_interest, no_entities\\n):\\n    \\\"\\\"\\\"\\n    This function extracts chi-squared test results for all combinations of news-outlets\\n    \\n    input: contingency_table\\n    \\n    ouput: None\\n    \\\"\\\"\\\"\\n\\n    # extracting a contingency table from a single reference entity\\n    i = 0\\n    j = 0\\n\\n    df_results = pd.DataFrame()\\n\\n    for i in range(len(relation_models)):\\n        for j in range(len(relation_models)):\\n            models = []\\n            models = [relation_models[i]] + [relation_models[j]]\\n\\n            contingency_table = build_contingency_table_from_single_topic(\\n                relation_models_path, models, topic_of_interest, no_entities\\n            )\\n\\n            contingency_table = sm.stats.Table(contingency_table)\\n            results = contingency_table.test_nominal_association()\\n\\n            df_results[\\n                str(relation_models[i][-10:-7])\\n                + \\\" - \\\"\\n                + str(relation_models[j][-10:-7])\\n            ] = [\\n                results.statistic,\\n                results.pvalue,\\n            ]\\n\\n    df_results = df_results.transpose()\\n    df_results = df_results.rename(columns={0: \\\"chi_sq\\\", 1: \\\"p_value\\\"})\\n    df_results\\n\\n    return df_results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def do_chi_squared_comparison(\n",
    "    relation_models_path, relation_models, topic_of_interest, no_entities\n",
    "):\n",
    "    \"\"\"\n",
    "    This function extracts chi-squared test results for all combinations of news-outlets\n",
    "    \n",
    "    input: contingency_table\n",
    "    \n",
    "    ouput: None\n",
    "    \"\"\"\n",
    "\n",
    "    # extracting a contingency table from a single reference entity\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(relation_models)):\n",
    "        for j in range(len(relation_models)):\n",
    "            models = []\n",
    "            models = [relation_models[i]] + [relation_models[j]]\n",
    "\n",
    "            contingency_table = build_contingency_table_from_single_topic(\n",
    "                relation_models_path, models, topic_of_interest, no_entities\n",
    "            )\n",
    "\n",
    "            contingency_table = sm.stats.Table(contingency_table)\n",
    "            results = contingency_table.test_nominal_association()\n",
    "\n",
    "            df_results[\n",
    "                str(relation_models[i][-10:-7])\n",
    "                + \" - \"\n",
    "                + str(relation_models[j][-10:-7])\n",
    "            ] = [\n",
    "                results.statistic,\n",
    "                results.pvalue,\n",
    "            ]\n",
    "\n",
    "    df_results = df_results.transpose()\n",
    "    df_results = df_results.rename(columns={0: \"chi_sq\", 1: \"p_value\"})\n",
    "    df_results\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"def entity_sentiment(reference_model):\\n    \\\"\\\"\\\"\\n    This function calculates the sentiment of the top co-occurring entities between a reference news outlet \\n    [reference_model] and other models. The sentiment is calculated of sentences which contain the co-occurring entity\\n    and neighbouring sentences within the scope of [SCOPE] sentences.\\n    Returns a dataframe with all necessary information\\n    \\n    Input:    reference_model (string)\\n              models (list)\\n              topic_of_interest (string)\\n    \\n    Output:   df_results (df)\\n    \\\"\\\"\\\"\\n    models = RELATION_MODELS\\n    topic_of_interest = TOPIC_OF_INTEREST\\n\\n    # initialize sentiment ananlyzer\\n    sid = SentimentIntensityAnalyzer()\\n    # extract list of top co-occurring entities\\n    dm = DistanceMeasure(RELATION_MODELS_PATH, str(reference_model))\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest, cutoff=NO_ENTITIES, e1_is_synset=0, e2_is_synset=1,\\n    )\\n    for i in range(len(top)):\\n        top[i] = top[i][0][:-5]\\n        top[i] = top[i].replace(\\\"_\\\", \\\" \\\")\\n\\n    df_results = pd.DataFrame()\\n\\n    # loop through all models\\n    for model in tqdm(models):\\n        if model == reference_model:\\n            continue\\n        else:\\n            # initialize db_handler\\n            description = str(str(reference_model[-10:-7]) + \\\"-\\\" + str(model[-10:-7]))\\n            db_handler = DBQueryHandlerCoocc(RELATION_MODELS_PATH, model)\\n            for topic in top:\\n                # retrieve co-occurrences without synsets\\n                articles = db_handler.get_articles_by_substring_text(topic)\\n                # convert generator (for count)\\n                articles = list(articles)\\n\\n                sentiment_of_topic = []\\n                try:\\n                    for single_article in articles:\\n                        # get text, lower it and tokenize it into sentences\\n                        article = single_article.text\\n                        article = article.lower()\\n                        article_tokenized = tokenizer.tokenize(article)\\n\\n                        # append buffers in the beginning and the end, in case the scope is overflowing\\n                        for i in range(0, SCOPE):\\n                            article_tokenized.append(\\\"buffer\\\")\\n                            article_tokenized.insert(0, \\\"buffer\\\")\\n\\n                        # extract compound sentiment score of each sector in a scope around the sentence\\n                        # in which the entity is mentioned\\n                        for line in range(0, len(article_tokenized)):\\n                            if TOPIC_OF_INTEREST in article_tokenized[line]:\\n                                sector = []\\n                                for i in range(line - SCOPE, line + 1 + SCOPE):\\n                                    sentiment = sid.polarity_scores(\\n                                        article_tokenized[i]\\n                                    )\\n                                    sector.append(sentiment[\\\"compound\\\"])\\n\\n                                # final sentiment as mean for the sector\\n                                final_sentiment = statistics.mean(sector)\\n                                # sentiment of topic as list for all final sentiments\\n                                sentiment_of_topic.append(final_sentiment)\\n\\n                    # extract parameters and print\\n                    mean_sentiment = statistics.mean(sentiment_of_topic)\\n                    median_sentiment = statistics.median(sentiment_of_topic)\\n                    \\\"\\\"\\\"\\n                    print(\\\"=\\\" * 100)\\n                    print(\\\"outlet: \\\" + description)\\n                    print(\\\"topic: \\\" + topic)\\n                    print(\\\"mean sentiment: \\\" + str(mean_sentiment))\\n                    print(\\\"median sentiment: \\\" + str(median_sentiment))\\n                    print(\\\"\\\\n\\\")\\n                    \\\"\\\"\\\"\\n                    results = [\\n                        [\\n                            str(reference_model[-10:-7]),\\n                            str(model[-10:-7]),\\n                            topic,\\n                            mean_sentiment,\\n                            median_sentiment,\\n                        ]\\n                    ]\\n                    df_results = df_results.append(results)\\n                except:\\n                    fail = [\\n                        [\\n                            str(reference_model[-10:-7]),\\n                            str(model[-10:-7]),\\n                            topic,\\n                            \\\"NaN\\\",\\n                            \\\"NaN\\\",\\n                        ]\\n                    ]\\n                    df_results = df_results.append(fail)\\n    df_results = df_results.rename(\\n        columns={\\n            0: \\\"reference\\\",\\n            1: \\\"comparison\\\",\\n            2: \\\"topic\\\",\\n            3: \\\"mean_sentiment\\\",\\n            4: \\\"median_sentiment\\\",\\n        }\\n    )\\n    df_results.reset_index()\\n    return df_results\";\n",
       "                var nbb_formatted_code = \"def entity_sentiment(reference_model):\\n    \\\"\\\"\\\"\\n    This function calculates the sentiment of the top co-occurring entities between a reference news outlet \\n    [reference_model] and other models. The sentiment is calculated of sentences which contain the co-occurring entity\\n    and neighbouring sentences within the scope of [SCOPE] sentences.\\n    Returns a dataframe with all necessary information\\n    \\n    Input:    reference_model (string)\\n              models (list)\\n              topic_of_interest (string)\\n    \\n    Output:   df_results (df)\\n    \\\"\\\"\\\"\\n    models = RELATION_MODELS\\n    topic_of_interest = TOPIC_OF_INTEREST\\n\\n    # initialize sentiment ananlyzer\\n    sid = SentimentIntensityAnalyzer()\\n    # extract list of top co-occurring entities\\n    dm = DistanceMeasure(RELATION_MODELS_PATH, str(reference_model))\\n    top = dm.get_top_co_occurrences(\\n        topic_of_interest, cutoff=NO_ENTITIES, e1_is_synset=0, e2_is_synset=1,\\n    )\\n    for i in range(len(top)):\\n        top[i] = top[i][0][:-5]\\n        top[i] = top[i].replace(\\\"_\\\", \\\" \\\")\\n\\n    df_results = pd.DataFrame()\\n\\n    # loop through all models\\n    for model in tqdm(models):\\n        if model == reference_model:\\n            continue\\n        else:\\n            # initialize db_handler\\n            description = str(str(reference_model[-10:-7]) + \\\"-\\\" + str(model[-10:-7]))\\n            db_handler = DBQueryHandlerCoocc(RELATION_MODELS_PATH, model)\\n            for topic in top:\\n                # retrieve co-occurrences without synsets\\n                articles = db_handler.get_articles_by_substring_text(topic)\\n                # convert generator (for count)\\n                articles = list(articles)\\n\\n                sentiment_of_topic = []\\n                try:\\n                    for single_article in articles:\\n                        # get text, lower it and tokenize it into sentences\\n                        article = single_article.text\\n                        article = article.lower()\\n                        article_tokenized = tokenizer.tokenize(article)\\n\\n                        # append buffers in the beginning and the end, in case the scope is overflowing\\n                        for i in range(0, SCOPE):\\n                            article_tokenized.append(\\\"buffer\\\")\\n                            article_tokenized.insert(0, \\\"buffer\\\")\\n\\n                        # extract compound sentiment score of each sector in a scope around the sentence\\n                        # in which the entity is mentioned\\n                        for line in range(0, len(article_tokenized)):\\n                            if TOPIC_OF_INTEREST in article_tokenized[line]:\\n                                sector = []\\n                                for i in range(line - SCOPE, line + 1 + SCOPE):\\n                                    sentiment = sid.polarity_scores(\\n                                        article_tokenized[i]\\n                                    )\\n                                    sector.append(sentiment[\\\"compound\\\"])\\n\\n                                # final sentiment as mean for the sector\\n                                final_sentiment = statistics.mean(sector)\\n                                # sentiment of topic as list for all final sentiments\\n                                sentiment_of_topic.append(final_sentiment)\\n\\n                    # extract parameters and print\\n                    mean_sentiment = statistics.mean(sentiment_of_topic)\\n                    median_sentiment = statistics.median(sentiment_of_topic)\\n                    \\\"\\\"\\\"\\n                    print(\\\"=\\\" * 100)\\n                    print(\\\"outlet: \\\" + description)\\n                    print(\\\"topic: \\\" + topic)\\n                    print(\\\"mean sentiment: \\\" + str(mean_sentiment))\\n                    print(\\\"median sentiment: \\\" + str(median_sentiment))\\n                    print(\\\"\\\\n\\\")\\n                    \\\"\\\"\\\"\\n                    results = [\\n                        [\\n                            str(reference_model[-10:-7]),\\n                            str(model[-10:-7]),\\n                            topic,\\n                            mean_sentiment,\\n                            median_sentiment,\\n                        ]\\n                    ]\\n                    df_results = df_results.append(results)\\n                except:\\n                    fail = [\\n                        [\\n                            str(reference_model[-10:-7]),\\n                            str(model[-10:-7]),\\n                            topic,\\n                            \\\"NaN\\\",\\n                            \\\"NaN\\\",\\n                        ]\\n                    ]\\n                    df_results = df_results.append(fail)\\n    df_results = df_results.rename(\\n        columns={\\n            0: \\\"reference\\\",\\n            1: \\\"comparison\\\",\\n            2: \\\"topic\\\",\\n            3: \\\"mean_sentiment\\\",\\n            4: \\\"median_sentiment\\\",\\n        }\\n    )\\n    df_results.reset_index()\\n    return df_results\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def entity_sentiment(reference_model):\n",
    "    \"\"\"\n",
    "    This function calculates the sentiment of the top co-occurring entities between a reference news outlet \n",
    "    [reference_model] and other models. The sentiment is calculated of sentences which contain the co-occurring entity\n",
    "    and neighbouring sentences within the scope of [SCOPE] sentences.\n",
    "    Returns a dataframe with all necessary information\n",
    "    \n",
    "    Input:    reference_model (string)\n",
    "              models (list)\n",
    "              topic_of_interest (string)\n",
    "    \n",
    "    Output:   df_results (df)\n",
    "    \"\"\"\n",
    "    models = RELATION_MODELS\n",
    "    topic_of_interest = TOPIC_OF_INTEREST\n",
    "\n",
    "    # initialize sentiment ananlyzer\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    # extract list of top co-occurring entities\n",
    "    dm = DistanceMeasure(RELATION_MODELS_PATH, str(reference_model))\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest, cutoff=NO_ENTITIES, e1_is_synset=0, e2_is_synset=1,\n",
    "    )\n",
    "    for i in range(len(top)):\n",
    "        top[i] = top[i][0][:-5]\n",
    "        top[i] = top[i].replace(\"_\", \" \")\n",
    "\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    # loop through all models\n",
    "    for model in tqdm(models):\n",
    "        if model == reference_model:\n",
    "            continue\n",
    "        else:\n",
    "            # initialize db_handler\n",
    "            description = str(str(reference_model[-10:-7]) + \"-\" + str(model[-10:-7]))\n",
    "            db_handler = DBQueryHandlerCoocc(RELATION_MODELS_PATH, model)\n",
    "            for topic in top:\n",
    "                # retrieve co-occurrences without synsets\n",
    "                articles = db_handler.get_articles_by_substring_text(topic)\n",
    "                # convert generator (for count)\n",
    "                articles = list(articles)\n",
    "\n",
    "                sentiment_of_topic = []\n",
    "                try:\n",
    "                    for single_article in articles:\n",
    "                        # get text, lower it and tokenize it into sentences\n",
    "                        article = single_article.text\n",
    "                        article = article.lower()\n",
    "                        article_tokenized = tokenizer.tokenize(article)\n",
    "\n",
    "                        # append buffers in the beginning and the end, in case the scope is overflowing\n",
    "                        for i in range(0, SCOPE):\n",
    "                            article_tokenized.append(\"buffer\")\n",
    "                            article_tokenized.insert(0, \"buffer\")\n",
    "\n",
    "                        # extract compound sentiment score of each sector in a scope around the sentence\n",
    "                        # in which the entity is mentioned\n",
    "                        for line in range(0, len(article_tokenized)):\n",
    "                            if TOPIC_OF_INTEREST in article_tokenized[line]:\n",
    "                                sector = []\n",
    "                                for i in range(line - SCOPE, line + 1 + SCOPE):\n",
    "                                    sentiment = sid.polarity_scores(\n",
    "                                        article_tokenized[i]\n",
    "                                    )\n",
    "                                    sector.append(sentiment[\"compound\"])\n",
    "\n",
    "                                # final sentiment as mean for the sector\n",
    "                                final_sentiment = statistics.mean(sector)\n",
    "                                # sentiment of topic as list for all final sentiments\n",
    "                                sentiment_of_topic.append(final_sentiment)\n",
    "\n",
    "                    # extract parameters and print\n",
    "                    mean_sentiment = statistics.mean(sentiment_of_topic)\n",
    "                    median_sentiment = statistics.median(sentiment_of_topic)\n",
    "                    \"\"\"\n",
    "                    print(\"=\" * 100)\n",
    "                    print(\"outlet: \" + description)\n",
    "                    print(\"topic: \" + topic)\n",
    "                    print(\"mean sentiment: \" + str(mean_sentiment))\n",
    "                    print(\"median sentiment: \" + str(median_sentiment))\n",
    "                    print(\"\\n\")\n",
    "                    \"\"\"\n",
    "                    results = [\n",
    "                        [\n",
    "                            str(reference_model[-10:-7]),\n",
    "                            str(model[-10:-7]),\n",
    "                            topic,\n",
    "                            mean_sentiment,\n",
    "                            median_sentiment,\n",
    "                        ]\n",
    "                    ]\n",
    "                    df_results = df_results.append(results)\n",
    "                except:\n",
    "                    fail = [\n",
    "                        [\n",
    "                            str(reference_model[-10:-7]),\n",
    "                            str(model[-10:-7]),\n",
    "                            topic,\n",
    "                            \"NaN\",\n",
    "                            \"NaN\",\n",
    "                        ]\n",
    "                    ]\n",
    "                    df_results = df_results.append(fail)\n",
    "    df_results = df_results.rename(\n",
    "        columns={\n",
    "            0: \"reference\",\n",
    "            1: \"comparison\",\n",
    "            2: \"topic\",\n",
    "            3: \"mean_sentiment\",\n",
    "            4: \"median_sentiment\",\n",
    "        }\n",
    "    )\n",
    "    df_results.reset_index()\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"def run_kmeans_on_sentiment(df):\\n    \\\"\\\"\\\"\\n    This function runs a k-mean clustering on the sentiment vectors of each given input news-outlet from\\n    the input df and returns a dataframe with the labels of the calculated clusters per entity.\\n\\n    input: df(Dataframe)\\n    \\n    output: df_res(Dataframe)\\n    \\n    \\\"\\\"\\\"\\n\\n    # splitting the df into list of dfs containing only one reference\\n    df_list = [df.loc[i : i + 80 - 1, :] for i in range(0, len(df), 80)]\\n\\n    # list of dataframes, that contain the sorted mean_sentiments of comparisons per reference-news-outlet\\n    entity_frame_list = []\\n\\n    for df_sublist in df_list:\\n        df_sublist = df_sublist.drop(columns=[\\\"reference\\\", \\\"median_sentiment\\\"])\\n        df_sublist = df_sublist.reset_index(drop=True)\\n\\n        df_subsublist = [\\n            df_sublist.loc[j : j + 10 - 1, :] for j in range(0, len(df_sublist), 10)\\n        ]\\n\\n        entity = pd.DataFrame()\\n\\n        for k in range(len(df_subsublist)):\\n            df_subsublist[k] = df_subsublist[k].reset_index(drop=True)\\n            s = df_subsublist[k][\\\"comparison\\\"][0]\\n            df_subsublist[k].index = df_subsublist[k][\\\"topic\\\"]\\n            df_subsublist[k] = df_subsublist[k].transpose()\\n            df_subsublist[k] = df_subsublist[k].drop(\\\"topic\\\")\\n            df_subsublist[k] = df_subsublist[k].drop(\\\"comparison\\\")\\n            df_subsublist[k].index = [s]\\n            entity = entity.append(df_subsublist[k])\\n\\n        entity_frame_list.append(entity)\\n\\n    # run k-means on the the sentiment vectors for each news-outlet and cluster into three groups\\n    df_res = pd.DataFrame(\\n        index=[\\\"NYT\\\", \\\"HFP\\\", \\\"WPO\\\", \\\"CNN\\\", \\\"RET\\\", \\\"NBC\\\", \\\"CTB\\\", \\\"FXN\\\", \\\"WSJ\\\"]\\n    )\\n\\n    for df in entity_frame_list:\\n        # NaNs are taken as neutral sentiment 0\\n        df = df.fillna(0)\\n        # clustering\\n        kmeans = KMeans(n_clusters=3).fit(df)\\n        # centroids = kmeans.cluster_centers_\\n        df[\\\"labels\\\"] = kmeans.labels_\\n\\n        df_res = pd.concat([df_res, df.labels], axis=1, sort=False)\\n\\n    return df_res, entity_frame_list\";\n",
       "                var nbb_formatted_code = \"def run_kmeans_on_sentiment(df):\\n    \\\"\\\"\\\"\\n    This function runs a k-mean clustering on the sentiment vectors of each given input news-outlet from\\n    the input df and returns a dataframe with the labels of the calculated clusters per entity.\\n\\n    input: df(Dataframe)\\n    \\n    output: df_res(Dataframe)\\n    \\n    \\\"\\\"\\\"\\n\\n    # splitting the df into list of dfs containing only one reference\\n    df_list = [df.loc[i : i + 80 - 1, :] for i in range(0, len(df), 80)]\\n\\n    # list of dataframes, that contain the sorted mean_sentiments of comparisons per reference-news-outlet\\n    entity_frame_list = []\\n\\n    for df_sublist in df_list:\\n        df_sublist = df_sublist.drop(columns=[\\\"reference\\\", \\\"median_sentiment\\\"])\\n        df_sublist = df_sublist.reset_index(drop=True)\\n\\n        df_subsublist = [\\n            df_sublist.loc[j : j + 10 - 1, :] for j in range(0, len(df_sublist), 10)\\n        ]\\n\\n        entity = pd.DataFrame()\\n\\n        for k in range(len(df_subsublist)):\\n            df_subsublist[k] = df_subsublist[k].reset_index(drop=True)\\n            s = df_subsublist[k][\\\"comparison\\\"][0]\\n            df_subsublist[k].index = df_subsublist[k][\\\"topic\\\"]\\n            df_subsublist[k] = df_subsublist[k].transpose()\\n            df_subsublist[k] = df_subsublist[k].drop(\\\"topic\\\")\\n            df_subsublist[k] = df_subsublist[k].drop(\\\"comparison\\\")\\n            df_subsublist[k].index = [s]\\n            entity = entity.append(df_subsublist[k])\\n\\n        entity_frame_list.append(entity)\\n\\n    # run k-means on the the sentiment vectors for each news-outlet and cluster into three groups\\n    df_res = pd.DataFrame(\\n        index=[\\\"NYT\\\", \\\"HFP\\\", \\\"WPO\\\", \\\"CNN\\\", \\\"RET\\\", \\\"NBC\\\", \\\"CTB\\\", \\\"FXN\\\", \\\"WSJ\\\"]\\n    )\\n\\n    for df in entity_frame_list:\\n        # NaNs are taken as neutral sentiment 0\\n        df = df.fillna(0)\\n        # clustering\\n        kmeans = KMeans(n_clusters=3).fit(df)\\n        # centroids = kmeans.cluster_centers_\\n        df[\\\"labels\\\"] = kmeans.labels_\\n\\n        df_res = pd.concat([df_res, df.labels], axis=1, sort=False)\\n\\n    return df_res, entity_frame_list\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_kmeans_on_sentiment(df):\n",
    "    \"\"\"\n",
    "    This function runs a k-mean clustering on the sentiment vectors of each given input news-outlet from\n",
    "    the input df and returns a dataframe with the labels of the calculated clusters per entity.\n",
    "\n",
    "    input: df(Dataframe)\n",
    "    \n",
    "    output: df_res(Dataframe)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # splitting the df into list of dfs containing only one reference\n",
    "    df_list = [df.loc[i : i + 80 - 1, :] for i in range(0, len(df), 80)]\n",
    "\n",
    "    # list of dataframes, that contain the sorted mean_sentiments of comparisons per reference-news-outlet\n",
    "    entity_frame_list = []\n",
    "\n",
    "    for df_sublist in df_list:\n",
    "        df_sublist = df_sublist.drop(columns=[\"reference\", \"median_sentiment\"])\n",
    "        df_sublist = df_sublist.reset_index(drop=True)\n",
    "\n",
    "        df_subsublist = [\n",
    "            df_sublist.loc[j : j + 10 - 1, :] for j in range(0, len(df_sublist), 10)\n",
    "        ]\n",
    "\n",
    "        entity = pd.DataFrame()\n",
    "\n",
    "        for k in range(len(df_subsublist)):\n",
    "            df_subsublist[k] = df_subsublist[k].reset_index(drop=True)\n",
    "            s = df_subsublist[k][\"comparison\"][0]\n",
    "            df_subsublist[k].index = df_subsublist[k][\"topic\"]\n",
    "            df_subsublist[k] = df_subsublist[k].transpose()\n",
    "            df_subsublist[k] = df_subsublist[k].drop(\"topic\")\n",
    "            df_subsublist[k] = df_subsublist[k].drop(\"comparison\")\n",
    "            df_subsublist[k].index = [s]\n",
    "            entity = entity.append(df_subsublist[k])\n",
    "\n",
    "        entity_frame_list.append(entity)\n",
    "\n",
    "    # run k-means on the the sentiment vectors for each news-outlet and cluster into three groups\n",
    "    df_res = pd.DataFrame(\n",
    "        index=[\"NYT\", \"HFP\", \"WPO\", \"CNN\", \"RET\", \"NBC\", \"CTB\", \"FXN\", \"WSJ\"]\n",
    "    )\n",
    "\n",
    "    for df in entity_frame_list:\n",
    "        # NaNs are taken as neutral sentiment 0\n",
    "        df = df.fillna(0)\n",
    "        # clustering\n",
    "        kmeans = KMeans(n_clusters=3).fit(df)\n",
    "        # centroids = kmeans.cluster_centers_\n",
    "        df[\"labels\"] = kmeans.labels_\n",
    "\n",
    "        df_res = pd.concat([df_res, df.labels], axis=1, sort=False)\n",
    "\n",
    "    return df_res, entity_frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib, ssl\n",
    "from getpass import getpass\n",
    "\n",
    "smtp_server = \"smtp.gmail.com\"\n",
    "port = 587  # For starttls\n",
    "sender_email = \"pythonserver.jonas.m.ehrhardt@gmail.com\"\n",
    "password = getpass()\n",
    "\n",
    "# Create a secure SSL context\n",
    "context = ssl.create_default_context()\n",
    "\n",
    "\n",
    "def message_me(calculation_ID):\n",
    "    \"\"\"\n",
    "    This function sends me an email, when called, with the calculation ID given in input ;) \n",
    "    \"\"\"\n",
    "    # Try to log in to server and send email\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, port)\n",
    "        server.ehlo()  # Can be omitted\n",
    "        server.starttls(context=context)  # Secure the connection\n",
    "        server.ehlo()  # Can be omitted\n",
    "        server.login(sender_email, password)\n",
    "\n",
    "        sender = \"pythonserver.jonas.m.ehrhardt@gmail.com\"\n",
    "        receivers = [\"jonas@xorentec.de\"]\n",
    "\n",
    "        message = (\n",
    "            \"From: Jonas Pythonserver\\nSubject: Calculation finished\\nThe Calculation \"\n",
    "            + calculation_ID\n",
    "            + \" is finished...\"\n",
    "        )\n",
    "\n",
    "        server.sendmail(sender, receivers, message)\n",
    "\n",
    "        print(\"Successfully sent email\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        server.quit()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_me(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final datasets <a class=\"anchor\" id=\"finalDatasets\"></a>\n",
    "\n",
    "Datasets used for the thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for parameter tuning\n",
    "# for the estiation of parameters number of entities and topic_of_interest\n",
    "#\n",
    "# -year:    2012\n",
    "# -domain:  news\n",
    "# -sources(left):    Huffington Post (HFP) 4909, New York Times (NYT) 2541,\n",
    "#         (center):  CNN (CNN) 2491, Reuters (RET) 2135\n",
    "#         (right):   FoxNews (FXN) 3784, (WSJ) 1215\n",
    "\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = (\n",
    "    \"/home/jonas/Documents/GitHub/MasterThesis/models/calibrationDataset\"\n",
    ")\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2012_news_HFP.sqlite\",\n",
    "    \"RM_2012_news_NYT.sqlite\",\n",
    "    \"RM_2012_news_CNN.sqlite\",\n",
    "    \"RM_2012_news_RET.sqlite\",\n",
    "    \"RM_2012_news_FXN.sqlite\",\n",
    "    \"RM_2012_news_WSJ.sqlite\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Dataset\n",
    "# final daset based on works of Budak (2016) Flaxmann (2016) and Groseclose (2015)\n",
    "#\n",
    "# -year:    2011\n",
    "# -domain:  news\n",
    "# -sources(left):    Huffington Post (HFP) 14876, LA Times (LAT) 445, New York Times (NYT) 11281,\n",
    "#                    Washington Post (WP) 14814, Daily KOS (DKO) 123\n",
    "#         (center):  BBC (BBC) 52, CNN (CNN) 2652, Reuters (RET) 16767, Yahoo News (YHN) 211\n",
    "#         (right):   Chicago Tribune (CTB) 2843, FoxNews (FXN) 6508, NBC (NBC) 3958, USA Today (UST) 171\n",
    "#                    Wall Street Journal (WSJ) 2522, Breitbart (BBT) 76\n",
    "\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/finalDataset\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2011_news_BBC.sqlite\",\n",
    "    \"RM_2011_news_BBT.sqlite\",\n",
    "    \"RM_2011_news_CNN.sqlite\",\n",
    "    \"RM_2011_news_CTB.sqlite\",\n",
    "    \"RM_2011_news_DKO.sqlite\",\n",
    "    \"RM_2011_news_FXN.sqlite\",\n",
    "    \"RM_2011_news_HFP.sqlite\",\n",
    "    \"RM_2011_news_LAT.sqlite\",\n",
    "    \"RM_2011_news_NBC.sqlite\",\n",
    "    \"RM_2011_news_NYT.sqlite\",\n",
    "    \"RM_2011_news_RET.sqlite\",\n",
    "    \"RM_2011_news_UST.sqlite\",\n",
    "    \"RM_2011_news_WPO.sqlite\",\n",
    "    \"RM_2011_news_WSJ.sqlite\",\n",
    "    \"RM_2011_news_YHN.sqlite\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Parameter tuning <a class=\"anchor\" id=\"parameterTuning\"></a>\n",
    "\n",
    "All parameter tuning is run with the [calibration dataset](#finalDatasets).\n",
    "The categorization in slant groups is derived from literature.\n",
    "\n",
    "\n",
    "## 4.1 n-entity estimation <a class=\"anchor\" id=\"nEntity\"></a>\n",
    "\n",
    "Here I estimated the number of co-occurring entities (n) with the calibration dataset. Therefore I observe the curve of the p-value of the chi-squared test over an increasing number of n. \n",
    "For same-slant group news-outlets the p-value is expected to be very low, for different-slant news-outlets it is expected to be high (check [hypothesis 1](#hyp1) for explanation). \n",
    "For a high n the p-value of the different-slant news-outlets is expected to decrease again. Hence the optimal n  has a high count for p-values below 0.05 for same-slant outlets and a high count for p-values above 0.05 for different-slant news-outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset and set hyper-parameters\n",
    "\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = (\n",
    "    \"/home/jonas/Documents/GitHub/MasterThesis/models/calibrationDataset\"\n",
    ")\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2012_news_HFP.sqlite\",\n",
    "    \"RM_2012_news_NYT.sqlite\",\n",
    "    \"RM_2012_news_CNN.sqlite\",\n",
    "    \"RM_2012_news_RET.sqlite\",\n",
    "    \"RM_2012_news_FXN.sqlite\",\n",
    "    \"RM_2012_news_WSJ.sqlite\",\n",
    "]\n",
    "\n",
    "# path to results folder\n",
    "RESULTS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/results/\"\n",
    "\n",
    "# max number of entities + 1, to compare with the reference entity\n",
    "NO_ENTITIES = 31\n",
    "\n",
    "# reference entity -\n",
    "TOPIC_OF_INTEREST = \"obama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate optimal n - within same-slant-constellations\n",
    "models = [\n",
    "    [RELATION_MODELS[0], RELATION_MODELS[1]],\n",
    "    [RELATION_MODELS[1], RELATION_MODELS[0]],\n",
    "    [RELATION_MODELS[2], RELATION_MODELS[3]],\n",
    "    [RELATION_MODELS[3], RELATION_MODELS[2]],\n",
    "    [RELATION_MODELS[4], RELATION_MODELS[5]],\n",
    "    [RELATION_MODELS[5], RELATION_MODELS[4]],\n",
    "]\n",
    "\n",
    "# initialize dataframes\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# loop through model constellation in models list\n",
    "def estimate_n_same_slant(models):\n",
    "    df_results = pd.DataFrame()\n",
    "    description = str(str(models[0][-10:-7]) + \"-\" + str(models[1][-10:-7]))\n",
    "    # loop through entity numbers until max entity is reached\n",
    "    for n in tnrange(1, NO_ENTITIES, desc=description):\n",
    "        # create SQL query and build contingency table for sm.stats\n",
    "        contingency_table = build_contingency_table_from_single_topic(\n",
    "            RELATION_MODELS_PATH, models, TOPIC_OF_INTEREST, n\n",
    "        )\n",
    "        contingency_table = sm.stats.Table(contingency_table)\n",
    "        # calculate results + add them to dataframe\n",
    "        results = contingency_table.test_nominal_association()\n",
    "        df_results[n] = [results.pvalue]\n",
    "\n",
    "    df_results = df_results.transpose()\n",
    "    df_results = df_results.rename(columns={0: description})\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n",
    "# Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# concat the pool-parallelized dataframes from pathlist\n",
    "df = pd.concat(pool.map(estimate_n_same_slant, [model for model in models]), axis=1)\n",
    "\n",
    "# close loop\n",
    "pool.close()\n",
    "\n",
    "\n",
    "# save results to csv\n",
    "df.to_csv(\n",
    "    RESULTS_PATH + \"nSameSlant_\" + TOPIC_OF_INTEREST + \".csv\", index=False\n",
    ")\n",
    "\n",
    "message_me(\"nSameSlant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df_same = pd.read_csv(RESULTS_PATH + \"nSameSlant_\" + TOPIC_OF_INTEREST + \".csv\")\n",
    "\n",
    "# Visualze dataset\n",
    "df_same.plot(kind=\"line\", figsize=(7.5, 7))\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.xlabel(\"n\")\n",
    "plt.title(\n",
    "    \"Behavior of p-values in relation to number of examined entities\\n within same slant groups - reference entitiy: \"\n",
    "    + TOPIC_OF_INTEREST\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate optimal n - within different-slant-constellations\n",
    "models = [\n",
    "    [RELATION_MODELS[0], RELATION_MODELS[2]],\n",
    "    [RELATION_MODELS[0], RELATION_MODELS[3]],\n",
    "    [RELATION_MODELS[0], RELATION_MODELS[4]],\n",
    "    [RELATION_MODELS[0], RELATION_MODELS[5]],\n",
    "    [RELATION_MODELS[1], RELATION_MODELS[2]],\n",
    "    [RELATION_MODELS[1], RELATION_MODELS[3]],\n",
    "    [RELATION_MODELS[1], RELATION_MODELS[4]],\n",
    "    [RELATION_MODELS[1], RELATION_MODELS[5]],\n",
    "    [RELATION_MODELS[2], RELATION_MODELS[0]],\n",
    "    [RELATION_MODELS[2], RELATION_MODELS[1]],\n",
    "    [RELATION_MODELS[2], RELATION_MODELS[4]],\n",
    "    [RELATION_MODELS[2], RELATION_MODELS[5]],\n",
    "    [RELATION_MODELS[3], RELATION_MODELS[0]],\n",
    "    [RELATION_MODELS[3], RELATION_MODELS[1]],\n",
    "    [RELATION_MODELS[3], RELATION_MODELS[4]],\n",
    "    [RELATION_MODELS[3], RELATION_MODELS[5]],\n",
    "    [RELATION_MODELS[4], RELATION_MODELS[0]],\n",
    "    [RELATION_MODELS[4], RELATION_MODELS[1]],\n",
    "    [RELATION_MODELS[4], RELATION_MODELS[2]],\n",
    "    [RELATION_MODELS[4], RELATION_MODELS[3]],\n",
    "    [RELATION_MODELS[5], RELATION_MODELS[0]],\n",
    "    [RELATION_MODELS[5], RELATION_MODELS[1]],\n",
    "    [RELATION_MODELS[5], RELATION_MODELS[2]],\n",
    "    [RELATION_MODELS[5], RELATION_MODELS[3]],\n",
    "]\n",
    "\n",
    "# initialize dataframes and counter for column name\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "def estimate_n_diff_slant(models):\n",
    "    # loop through model constellation in models list\n",
    "    # for constellation in tqdm(models):\n",
    "    df_results = pd.DataFrame()\n",
    "    description = str(str(models[0][-10:-7]) + \"-\" + str(models[1][-10:-7]))\n",
    "    # loop through entity numbers until max entity is reached\n",
    "    for n in tnrange(1, NO_ENTITIES, desc=description):\n",
    "\n",
    "        # create SQL query and build contingency table for sm.stats\n",
    "        contingency_table = build_contingency_table_from_single_topic(\n",
    "            RELATION_MODELS_PATH, models, TOPIC_OF_INTEREST, n\n",
    "        )\n",
    "        contingency_table = sm.stats.Table(contingency_table)\n",
    "        # calculate results + add them to dataframe\n",
    "        results = contingency_table.test_nominal_association()\n",
    "        df_results[n] = [results.pvalue]\n",
    "\n",
    "    df_results = df_results.transpose()\n",
    "    df_results = df_results.rename(columns={0: description})\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "# Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# concat the pool-parallelized dataframes from pathlist\n",
    "df = pd.concat(pool.map(estimate_n_diff_slant, [model for model in models]), axis=1)\n",
    "\n",
    "# close loop\n",
    "pool.close()\n",
    "\n",
    "\n",
    "# save results to csv\n",
    "df.to_csv(\n",
    "    RESULTS_PATH + \"nDiffSlant_\" + TOPIC_OF_INTEREST + \".csv\", index=False\n",
    ")\n",
    "\n",
    "message_me(\"nDiffSlant_All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df_diff = pd.read_csv(RESULTS_PATH + \"nDiffSlant_\" + TOPIC_OF_INTEREST + \".csv\")\n",
    "\n",
    "# Visualze\n",
    "df_diff.plot(kind=\"line\", figsize=(7.5, 7.0))\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.title(\n",
    "    \"Behavior of p-values in relation to number of examined entities \\nbetween different slant groups - reference entity: \"\n",
    "    + TOPIC_OF_INTEREST\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Reference entity estimation <a class=\"anchor\" id=\"refEntity\"></a>\n",
    "\n",
    "To estimate the optimal reference entity for the co-occurrences, the behavior of different and same-slant news-outlets are compared. A good reference entity gets high p-values for different-slant news-outlets and low p-values for same-slant news-outlets.\n",
    "The tested entities are derived from Gentzkow and Shapiro (2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = (\n",
    "    \"/home/jonas/Documents/GitHub/MasterThesis/models/calibrationDataset\"\n",
    ")\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2012_news_HFP.sqlite\",\n",
    "    \"RM_2012_news_NYT.sqlite\",\n",
    "    \"RM_2012_news_CNN.sqlite\",\n",
    "    \"RM_2012_news_RET.sqlite\",\n",
    "    \"RM_2012_news_FXN.sqlite\",\n",
    "    \"RM_2012_news_WSJ.sqlite\",\n",
    "]\n",
    "\n",
    "# path to results folder\n",
    "RESULTS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/results/\"\n",
    "\n",
    "# number of entities to compare with the reference entitiy\n",
    "NO_ENTITIES = 16\n",
    "\n",
    "# reference entities\n",
    "TOPIC_OF_INTEREST_LIST = [\n",
    "    \"sport\",\n",
    "    \"obama\",\n",
    "    \"bush\",\n",
    "    \"united_states\",\n",
    "    \"healthcare\",\n",
    "    \"insurance\",\n",
    "    \"gun\",\n",
    "    \"school\",\n",
    "    \"death_tax\",\n",
    "    \"terrorism\",\n",
    "    \"Germany\",\n",
    "    \"France\",\n",
    "    \"health_care\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframes and counter for column name\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# same-slant news-outlets\n",
    "models = [RELATION_MODELS[0], RELATION_MODELS[1]]\n",
    "# different-slant news-outlets\n",
    "# models = [RELATION_MODELS[0], RELATION_MODELS[4]]\n",
    "\n",
    "def estimate_optimal_reference_entity(topic):\n",
    "    # loop through model constellation in models list\n",
    "    # for constellation in tqdm(models):\n",
    "    df_results = pd.DataFrame()\n",
    "    description = str(str(models[0][-10:-7]) + \"-\" + str(models[1][-10:-7]))\n",
    "    # loop through entity numbers until max entity is reached\n",
    "    for n in tnrange(1, NO_ENTITIES, desc=topic):\n",
    "        try:\n",
    "            # create SQL query and build contingency table for sm.stats\n",
    "            contingency_table = build_contingency_table_from_single_topic(\n",
    "                RELATION_MODELS_PATH, models, topic, n\n",
    "            )\n",
    "            contingency_table = sm.stats.Table(contingency_table)\n",
    "            # calculate results + add them to dataframe\n",
    "            results = contingency_table.test_nominal_association()\n",
    "            df_results[n] = [results.pvalue]\n",
    "        except:\n",
    "            print(\"There is too little data for \" + topic)\n",
    "            break\n",
    "\n",
    "    df_results = df_results.transpose()\n",
    "    df_results = df_results.rename(columns={0: topic})\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "# Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# concat the pool-parallelized dataframes from pathlist\n",
    "df = pd.concat(\n",
    "    pool.map(estimate_optimal_reference_entity, [topic for topic in TOPIC_OF_INTEREST_LIST]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# close pool\n",
    "pool.close()\n",
    "\n",
    "# save results to csv\n",
    "df.to_csv(RESULTS_PATH + \"reference_entity_estimation_diff.csv\", index=False)\n",
    "# df.to_csv(RESULTS_PATH + \"reference_entity_estimation_same.csv\", index=False)\n",
    "\n",
    "message_me(\"reference_estimation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and visualize - same-slant news-outlet\n",
    "df_same = pd.read_csv(RESULTS_PATH + \"reference_entity_estimation_same.csv\")\n",
    "\n",
    "df_same.plot(kind=\"line\", figsize=(7.5, 4))\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.title(\n",
    "    \"Behavior of p-values in relation to the chosen\\nreference entity - same-slant newsoutlet\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Import and visualize - diff-slant news-outlet\n",
    "df_diff = pd.read_csv(RESULTS_PATH + \"reference_entity_estimation_diff.csv\")\n",
    "\n",
    "df_diff.plot(kind=\"line\", figsize=(7.5, 4))\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.title(\n",
    "    \"Behavior of p-values in relation to the chosen\\nreference entity - different-slant newsoutlet\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Hypothesis testing <a class=\"anchor\" id=\"hypothesisTesting\"></a>\n",
    "\n",
    "## 5.1 Hypothesis 1<a class=\"anchor\" id=\"hyp1\"></a>\n",
    "\n",
    "1.1 Within same slant groups the co-occurring entities are independent from the news-outlet\n",
    "\n",
    "1.2 Between different slant groups the co-occurring entities are dependent from the news-outlet\n",
    "    \n",
    "To check hypothesis 1 I ran chi-squared tests for same (1.1) and different-slant (1.2) news-outlets.\n",
    "The results are matched with news-outlet groupings from literature. Accuracy, precision, recall and F1-score are estimated individually and combined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# directory path of relation models\\nRELATION_MODELS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/models/finalDataset\\\"\\n\\n# model names\\nRELATION_MODELS = [\\n    \\\"RM_2011_news_CNN.sqlite\\\",\\n    \\\"RM_2011_news_CTB.sqlite\\\",\\n    \\\"RM_2011_news_FXN.sqlite\\\",\\n    \\\"RM_2011_news_HFP.sqlite\\\",\\n    \\\"RM_2011_news_NBC.sqlite\\\",\\n    \\\"RM_2011_news_NYT.sqlite\\\",\\n    \\\"RM_2011_news_RET.sqlite\\\",\\n    \\\"RM_2011_news_WPO.sqlite\\\",\\n    \\\"RM_2011_news_WSJ.sqlite\\\",\\n]\\n\\n# path to results folder\\nRESULTS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/results/\\\"\\n\\n# reference entity\\nTOPIC_OF_INTEREST = \\\"SPECIFIC_ENTITY_TF_IDF_approach\\\"\\n\\n# number of co-occurring entities + 1\\nNO_ENTITIES = 11\";\n",
       "                var nbb_formatted_code = \"# directory path of relation models\\nRELATION_MODELS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/models/finalDataset\\\"\\n\\n# model names\\nRELATION_MODELS = [\\n    \\\"RM_2011_news_CNN.sqlite\\\",\\n    \\\"RM_2011_news_CTB.sqlite\\\",\\n    \\\"RM_2011_news_FXN.sqlite\\\",\\n    \\\"RM_2011_news_HFP.sqlite\\\",\\n    \\\"RM_2011_news_NBC.sqlite\\\",\\n    \\\"RM_2011_news_NYT.sqlite\\\",\\n    \\\"RM_2011_news_RET.sqlite\\\",\\n    \\\"RM_2011_news_WPO.sqlite\\\",\\n    \\\"RM_2011_news_WSJ.sqlite\\\",\\n]\\n\\n# path to results folder\\nRESULTS_PATH = \\\"/home/jonas/Documents/GitHub/MasterThesis/results/\\\"\\n\\n# reference entity\\nTOPIC_OF_INTEREST = \\\"SPECIFIC_ENTITY_TF_IDF_approach\\\"\\n\\n# number of co-occurring entities + 1\\nNO_ENTITIES = 11\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/finalDataset\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2011_news_CNN.sqlite\",\n",
    "    \"RM_2011_news_CTB.sqlite\",\n",
    "    \"RM_2011_news_FXN.sqlite\",\n",
    "    \"RM_2011_news_HFP.sqlite\",\n",
    "    \"RM_2011_news_NBC.sqlite\",\n",
    "    \"RM_2011_news_NYT.sqlite\",\n",
    "    \"RM_2011_news_RET.sqlite\",\n",
    "    \"RM_2011_news_WPO.sqlite\",\n",
    "    \"RM_2011_news_WSJ.sqlite\",\n",
    "]\n",
    "\n",
    "# path to results folder\n",
    "RESULTS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/results/\"\n",
    "\n",
    "# reference entity\n",
    "TOPIC_OF_INTEREST = \"SPECIFIC_ENTITY_TF_IDF_approach\"\n",
    "\n",
    "# number of co-occurring entities + 1\n",
    "NO_ENTITIES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idfs = []\n",
    "\n",
    "for model in RELATION_MODELS:\n",
    "    df = create_tf_idf_table(RELATION_MODELS_PATH, model)\n",
    "    tf_idfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for LDA approach\n",
    "\n",
    "top_terms = [\n",
    "    \"people\",\n",
    "    \"obama\",\n",
    "    \"romney\",\n",
    "    \"percent\",\n",
    "    \"game\",\n",
    "    \"state\",\n",
    "    \"president\",\n",
    "    \"police\",\n",
    "    \"street\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# for tf_idf\\n\\ntop_terms = [\\n    \\\"deregulation\\\",\\n    \\\"latching\\\",\\n    \\\"katalin\\\",\\n    \\\"\\ufb02edged\\\",\\n    \\\"plumper\\\",\\n    \\\"plundered\\\",\\n    \\\"larders\\\",\\n    \\\"decmberists\\\",\\n    \\\"omitting\\\",\\n]\";\n",
       "                var nbb_formatted_code = \"# for tf_idf\\n\\ntop_terms = [\\n    \\\"deregulation\\\",\\n    \\\"latching\\\",\\n    \\\"katalin\\\",\\n    \\\"\\ufb02edged\\\",\\n    \\\"plumper\\\",\\n    \\\"plundered\\\",\\n    \\\"larders\\\",\\n    \\\"decmberists\\\",\\n    \\\"omitting\\\",\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for tf_idf\n",
    "\n",
    "top_terms = [\n",
    "    \"deregulation\",\n",
    "    \"latching\",\n",
    "    \"katalin\",\n",
    "    \"edged\",\n",
    "    \"plumper\",\n",
    "    \"plundered\",\n",
    "    \"larders\",\n",
    "    \"decmberists\",\n",
    "    \"omitting\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for first try - self generated terms \n",
    "top_terms = [\n",
    "    \"challenge\",\n",
    "    \"obama\",\n",
    "    \"romney\",\n",
    "    \"dangerous\",\n",
    "    \"administration\",\n",
    "    \"corruption\",\n",
    "    \"china\",\n",
    "    \"oil\",\n",
    "    \"iran\",\n",
    "]\n",
    "\n",
    "# for _last_specific approach\n",
    "top_terms = [\n",
    "    \"challenge\",\n",
    "    \"obama\",\n",
    "    \"romney\",\n",
    "    \"dangerous\",\n",
    "    \"administration\",\n",
    "    \"corruption\",\n",
    "    \"illegal\",\n",
    "    \"border\",\n",
    "    \"fail\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"N = 1\\n\\\"\\\"\\\"\\ntop_terms = []\\nfor df in tf_idfs:\\n    df = df.transpose()\\n    df = df[0].sort_values(ascending=False)\\n    top_terms.extend(df.index[:1])\\n\\ntop_terms = list(dict.fromkeys(top_terms))\\n\\\"\\\"\\\"\\npreset_cooccurrences = []\\nfor i in top_terms:\\n    for j in top_terms:\\n        if i != j:\\n            single_tuple = (i, j)\\n            preset_cooccurrences.append(single_tuple)\\nlen(preset_cooccurrences)\";\n",
       "                var nbb_formatted_code = \"N = 1\\n\\\"\\\"\\\"\\ntop_terms = []\\nfor df in tf_idfs:\\n    df = df.transpose()\\n    df = df[0].sort_values(ascending=False)\\n    top_terms.extend(df.index[:1])\\n\\ntop_terms = list(dict.fromkeys(top_terms))\\n\\\"\\\"\\\"\\npreset_cooccurrences = []\\nfor i in top_terms:\\n    for j in top_terms:\\n        if i != j:\\n            single_tuple = (i, j)\\n            preset_cooccurrences.append(single_tuple)\\nlen(preset_cooccurrences)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 1\n",
    "\"\"\"\n",
    "top_terms = []\n",
    "for df in tf_idfs:\n",
    "    df = df.transpose()\n",
    "    df = df[0].sort_values(ascending=False)\n",
    "    top_terms.extend(df.index[:1])\n",
    "\n",
    "top_terms = list(dict.fromkeys(top_terms))\n",
    "\"\"\"\n",
    "preset_cooccurrences = []\n",
    "for i in top_terms:\n",
    "    for j in top_terms:\n",
    "        if i != j:\n",
    "            single_tuple = (i, j)\n",
    "            preset_cooccurrences.append(single_tuple)\n",
    "len(preset_cooccurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"raw_cooccurrences = []\\n\\ndef hello_kitty_action_plan(model):\\n    contingency_table = build_contingency_table_from_preset_cooccurrences(\\n        RELATION_MODELS_PATH, model, preset_cooccurrences\\n    )\\n    return contingency_table\\n\\n\\n# open multiprocessing pool\\npool = mp.Pool(mp.cpu_count())\\n\\n# multiprocessing\\nraw_cooccurrences.append(pool.map(hello_kitty_action_plan, RELATION_MODELS))\\n\\n# close pool\\npool.close()\\n\\nraw_cooccurrences = raw_cooccurrences[0]\";\n",
       "                var nbb_formatted_code = \"raw_cooccurrences = []\\n\\n\\ndef hello_kitty_action_plan(model):\\n    contingency_table = build_contingency_table_from_preset_cooccurrences(\\n        RELATION_MODELS_PATH, model, preset_cooccurrences\\n    )\\n    return contingency_table\\n\\n\\n# open multiprocessing pool\\npool = mp.Pool(mp.cpu_count())\\n\\n# multiprocessing\\nraw_cooccurrences.append(pool.map(hello_kitty_action_plan, RELATION_MODELS))\\n\\n# close pool\\npool.close()\\n\\nraw_cooccurrences = raw_cooccurrences[0]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_cooccurrences = []\n",
    "\n",
    "def hello_kitty_action_plan(model):\n",
    "    contingency_table = build_contingency_table_from_preset_cooccurrences(\n",
    "        RELATION_MODELS_PATH, model, preset_cooccurrences\n",
    "    )\n",
    "    return contingency_table\n",
    "\n",
    "\n",
    "# open multiprocessing pool\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# multiprocessing\n",
    "raw_cooccurrences.append(pool.map(hello_kitty_action_plan, RELATION_MODELS))\n",
    "\n",
    "# close pool\n",
    "pool.close()\n",
    "\n",
    "raw_cooccurrences = raw_cooccurrences[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"df = pd.DataFrame()\\n# compare everything with everything\\nfor i in range(len(raw_cooccurrences)):\\n    for j in range(len(raw_cooccurrences)):\\n        if i != j:\\n            contingency_table = pd.DataFrame()\\n            df_results = pd.DataFrame()\\n            description = (\\n                raw_cooccurrences[i][0].index[0][-10:-7]\\n                + \\\"-\\\"\\n                + raw_cooccurrences[j][0].index[0][-10:-7]\\n            )\\n            contingency_table = pd.concat(\\n                [raw_cooccurrences[i], raw_cooccurrences[j]], axis=0\\n            )\\n            contingency_table = sm.stats.Table(contingency_table)\\n\\n            # calculate results + add them to dataframe\\n            results = contingency_table.test_nominal_association()\\n\\n            df_results[description] = [\\n                raw_cooccurrences[i][0].index[0][-10:-7],\\n                raw_cooccurrences[j][0].index[0][-10:-7],\\n                description,\\n                results.statistic,\\n                results.pvalue,\\n            ]\\n\\n            df_results = df_results.transpose()\\n            df_results = df_results.rename(\\n                columns={\\n                    0: \\\"reference\\\",\\n                    1: \\\"comparison\\\",\\n                    2: \\\"combination\\\",\\n                    3: str(\\\"chi_sq\\\"),\\n                    4: str(\\\"p_value\\\"),\\n                }\\n            )\\n            df = pd.concat([df, df_results], axis=0)\\n\\n\\n# save results to csv\\ndf.to_csv(RESULTS_PATH + \\\"hyp1_\\\" + TOPIC_OF_INTEREST + \\\".csv\\\", index=False)\";\n",
       "                var nbb_formatted_code = \"df = pd.DataFrame()\\n# compare everything with everything\\nfor i in range(len(raw_cooccurrences)):\\n    for j in range(len(raw_cooccurrences)):\\n        if i != j:\\n            contingency_table = pd.DataFrame()\\n            df_results = pd.DataFrame()\\n            description = (\\n                raw_cooccurrences[i][0].index[0][-10:-7]\\n                + \\\"-\\\"\\n                + raw_cooccurrences[j][0].index[0][-10:-7]\\n            )\\n            contingency_table = pd.concat(\\n                [raw_cooccurrences[i], raw_cooccurrences[j]], axis=0\\n            )\\n            contingency_table = sm.stats.Table(contingency_table)\\n\\n            # calculate results + add them to dataframe\\n            results = contingency_table.test_nominal_association()\\n\\n            df_results[description] = [\\n                raw_cooccurrences[i][0].index[0][-10:-7],\\n                raw_cooccurrences[j][0].index[0][-10:-7],\\n                description,\\n                results.statistic,\\n                results.pvalue,\\n            ]\\n\\n            df_results = df_results.transpose()\\n            df_results = df_results.rename(\\n                columns={\\n                    0: \\\"reference\\\",\\n                    1: \\\"comparison\\\",\\n                    2: \\\"combination\\\",\\n                    3: str(\\\"chi_sq\\\"),\\n                    4: str(\\\"p_value\\\"),\\n                }\\n            )\\n            df = pd.concat([df, df_results], axis=0)\\n\\n\\n# save results to csv\\ndf.to_csv(RESULTS_PATH + \\\"hyp1_\\\" + TOPIC_OF_INTEREST + \\\".csv\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "# compare everything with everything\n",
    "for i in range(len(raw_cooccurrences)):\n",
    "    for j in range(len(raw_cooccurrences)):\n",
    "        if i != j:\n",
    "            contingency_table = pd.DataFrame()\n",
    "            df_results = pd.DataFrame()\n",
    "            description = (\n",
    "                raw_cooccurrences[i][0].index[0][-10:-7]\n",
    "                + \"-\"\n",
    "                + raw_cooccurrences[j][0].index[0][-10:-7]\n",
    "            )\n",
    "            contingency_table = pd.concat(\n",
    "                [raw_cooccurrences[i], raw_cooccurrences[j]], axis=0\n",
    "            )\n",
    "            contingency_table = sm.stats.Table(contingency_table)\n",
    "\n",
    "            # calculate results + add them to dataframe\n",
    "            results = contingency_table.test_nominal_association()\n",
    "\n",
    "            df_results[description] = [\n",
    "                raw_cooccurrences[i][0].index[0][-10:-7],\n",
    "                raw_cooccurrences[j][0].index[0][-10:-7],\n",
    "                description,\n",
    "                results.statistic,\n",
    "                results.pvalue,\n",
    "            ]\n",
    "\n",
    "            df_results = df_results.transpose()\n",
    "            df_results = df_results.rename(\n",
    "                columns={\n",
    "                    0: \"reference\",\n",
    "                    1: \"comparison\",\n",
    "                    2: \"combination\",\n",
    "                    3: str(\"chi_sq\"),\n",
    "                    4: str(\"p_value\"),\n",
    "                }\n",
    "            )\n",
    "            df = pd.concat([df, df_results], axis=0)\n",
    "\n",
    "\n",
    "# save results to csv\n",
    "df.to_csv(RESULTS_PATH + \"hyp1_\" + TOPIC_OF_INTEREST + \".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare everything with everything\n",
    "models = []\n",
    "\n",
    "# set up list of model combinations\n",
    "for i in RELATION_MODELS:\n",
    "    for j in RELATION_MODELS:\n",
    "        if i == j:\n",
    "            continue\n",
    "        else:\n",
    "            models.append([i, j])\n",
    "\n",
    "# initialize dataframes and counter for column name\n",
    "df = pd.DataFrame()\n",
    "\n",
    "def hello_kitty_action_plan(models):\n",
    "    # loop through model constellation in models list\n",
    "    df_results = pd.DataFrame()\n",
    "    description = str(str(models[0][-10:-7]) + \"-\" + str(models[1][-10:-7]))\n",
    "    try:\n",
    "        # create SQL query and build contingency table for sm.stats\n",
    "        contingency_table = build_contingency_table_from_single_topic(\n",
    "            RELATION_MODELS_PATH, models, TOPIC_OF_INTEREST, NO_ENTITIES\n",
    "        )\n",
    "        contingency_table = sm.stats.Table(contingency_table)\n",
    "        # calculate results + add them to dataframe\n",
    "        results = contingency_table.test_nominal_association()\n",
    "        df_results[description] = [str(models[0][-10:-7]), str(models[1][-10:-7]), description, results.statistic, results.pvalue]\n",
    "    except:\n",
    "        print(\"There is too little data for \" + TOPIC_OF_INTEREST)\n",
    "\n",
    "    df_results = df_results.transpose()\n",
    "    df_results = df_results.rename(columns={0: \"reference\", 1:\"comparison\", 2: \"combination\", 3: str(\"chi_sq\"), 4: str(\"p_value\")})\n",
    "\n",
    "    return df_results\n",
    "\n",
    "\n",
    "# Init multiprocessing.Pool()\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "# concat the pool-parallelized dataframes from pathlist\n",
    "df = pd.concat(pool.map(hello_kitty_action_plan, [model for model in models]), axis=0)\n",
    "\n",
    "# close pool \n",
    "pool.close()\n",
    "\n",
    "# save results to csv\n",
    "df.to_csv(\n",
    "    RESULTS_PATH + \"hyp1_\" + TOPIC_OF_INTEREST + \".csv\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "message_me(\"hyp1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# TOPIC_OF_INTEREST = \\\"hyp1_obama.csv\\\"\\nTOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_TF_IDF_approach.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_approach.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_last_last_approach.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_last_last_approach_Z.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_LDA_approach.csv\\\"\";\n",
       "                var nbb_formatted_code = \"# TOPIC_OF_INTEREST = \\\"hyp1_obama.csv\\\"\\nTOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_TF_IDF_approach.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_approach.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_last_last_approach.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_last_last_approach_Z.csv\\\"\\n# TOPIC_OF_INTEREST = \\\"hyp1_SPECIFIC_ENTITY_LDA_approach.csv\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TOPIC_OF_INTEREST = \"hyp1_obama.csv\"\n",
    "TOPIC_OF_INTEREST = \"hyp1_SPECIFIC_ENTITY_TF_IDF_approach.csv\"\n",
    "# TOPIC_OF_INTEREST = \"hyp1_SPECIFIC_ENTITY_approach.csv\"\n",
    "# TOPIC_OF_INTEREST = \"hyp1_SPECIFIC_ENTITY_last_last_approach.csv\"\n",
    "# TOPIC_OF_INTEREST = \"hyp1_SPECIFIC_ENTITY_last_last_approach_Z.csv\"\n",
    "# TOPIC_OF_INTEREST = \"hyp1_SPECIFIC_ENTITY_LDA_approach.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>comparison</th>\n",
       "      <th>combination</th>\n",
       "      <th>chi_sq</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>CTB</td>\n",
       "      <td>CNN-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNN</td>\n",
       "      <td>FXN</td>\n",
       "      <td>CNN-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CNN</td>\n",
       "      <td>HFP</td>\n",
       "      <td>CNN-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNN</td>\n",
       "      <td>NBC</td>\n",
       "      <td>CNN-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>NYT</td>\n",
       "      <td>CNN-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CNN</td>\n",
       "      <td>RET</td>\n",
       "      <td>CNN-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CNN</td>\n",
       "      <td>WPO</td>\n",
       "      <td>CNN-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>CNN-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CTB</td>\n",
       "      <td>CNN</td>\n",
       "      <td>CTB-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CTB</td>\n",
       "      <td>FXN</td>\n",
       "      <td>CTB-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CTB</td>\n",
       "      <td>HFP</td>\n",
       "      <td>CTB-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CTB</td>\n",
       "      <td>NBC</td>\n",
       "      <td>CTB-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CTB</td>\n",
       "      <td>NYT</td>\n",
       "      <td>CTB-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CTB</td>\n",
       "      <td>RET</td>\n",
       "      <td>CTB-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CTB</td>\n",
       "      <td>WPO</td>\n",
       "      <td>CTB-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CTB</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>CTB-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FXN</td>\n",
       "      <td>CNN</td>\n",
       "      <td>FXN-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>FXN</td>\n",
       "      <td>CTB</td>\n",
       "      <td>FXN-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FXN</td>\n",
       "      <td>HFP</td>\n",
       "      <td>FXN-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FXN</td>\n",
       "      <td>NBC</td>\n",
       "      <td>FXN-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FXN</td>\n",
       "      <td>NYT</td>\n",
       "      <td>FXN-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FXN</td>\n",
       "      <td>RET</td>\n",
       "      <td>FXN-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>FXN</td>\n",
       "      <td>WPO</td>\n",
       "      <td>FXN-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>FXN</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>FXN-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HFP</td>\n",
       "      <td>CNN</td>\n",
       "      <td>HFP-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HFP</td>\n",
       "      <td>CTB</td>\n",
       "      <td>HFP-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HFP</td>\n",
       "      <td>FXN</td>\n",
       "      <td>HFP-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HFP</td>\n",
       "      <td>NBC</td>\n",
       "      <td>HFP-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HFP</td>\n",
       "      <td>NYT</td>\n",
       "      <td>HFP-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HFP</td>\n",
       "      <td>RET</td>\n",
       "      <td>HFP-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>HFP</td>\n",
       "      <td>WPO</td>\n",
       "      <td>HFP-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>HFP</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>HFP-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NBC</td>\n",
       "      <td>CNN</td>\n",
       "      <td>NBC-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NBC</td>\n",
       "      <td>CTB</td>\n",
       "      <td>NBC-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NBC</td>\n",
       "      <td>FXN</td>\n",
       "      <td>NBC-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NBC</td>\n",
       "      <td>HFP</td>\n",
       "      <td>NBC-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NBC</td>\n",
       "      <td>NYT</td>\n",
       "      <td>NBC-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NBC</td>\n",
       "      <td>RET</td>\n",
       "      <td>NBC-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NBC</td>\n",
       "      <td>WPO</td>\n",
       "      <td>NBC-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NBC</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>NBC-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NYT</td>\n",
       "      <td>CNN</td>\n",
       "      <td>NYT-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NYT</td>\n",
       "      <td>CTB</td>\n",
       "      <td>NYT-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NYT</td>\n",
       "      <td>FXN</td>\n",
       "      <td>NYT-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NYT</td>\n",
       "      <td>HFP</td>\n",
       "      <td>NYT-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NYT</td>\n",
       "      <td>NBC</td>\n",
       "      <td>NYT-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NYT</td>\n",
       "      <td>RET</td>\n",
       "      <td>NYT-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NYT</td>\n",
       "      <td>WPO</td>\n",
       "      <td>NYT-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NYT</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>NYT-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RET</td>\n",
       "      <td>CNN</td>\n",
       "      <td>RET-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RET</td>\n",
       "      <td>CTB</td>\n",
       "      <td>RET-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>RET</td>\n",
       "      <td>FXN</td>\n",
       "      <td>RET-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RET</td>\n",
       "      <td>HFP</td>\n",
       "      <td>RET-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RET</td>\n",
       "      <td>NBC</td>\n",
       "      <td>RET-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RET</td>\n",
       "      <td>NYT</td>\n",
       "      <td>RET-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RET</td>\n",
       "      <td>WPO</td>\n",
       "      <td>RET-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RET</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>RET-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>WPO</td>\n",
       "      <td>CNN</td>\n",
       "      <td>WPO-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>WPO</td>\n",
       "      <td>CTB</td>\n",
       "      <td>WPO-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>WPO</td>\n",
       "      <td>FXN</td>\n",
       "      <td>WPO-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>WPO</td>\n",
       "      <td>HFP</td>\n",
       "      <td>WPO-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>WPO</td>\n",
       "      <td>NBC</td>\n",
       "      <td>WPO-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>WPO</td>\n",
       "      <td>NYT</td>\n",
       "      <td>WPO-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>WPO</td>\n",
       "      <td>RET</td>\n",
       "      <td>WPO-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>WPO</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>WPO-WSJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>CNN</td>\n",
       "      <td>WSJ-CNN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>CTB</td>\n",
       "      <td>WSJ-CTB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>FXN</td>\n",
       "      <td>WSJ-FXN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>HFP</td>\n",
       "      <td>WSJ-HFP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>NBC</td>\n",
       "      <td>WSJ-NBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>NYT</td>\n",
       "      <td>WSJ-NYT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>RET</td>\n",
       "      <td>WSJ-RET</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>WSJ</td>\n",
       "      <td>WPO</td>\n",
       "      <td>WSJ-WPO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference comparison combination  chi_sq  p_value\n",
       "0        CNN        CTB     CNN-CTB     0.0      1.0\n",
       "1        CNN        FXN     CNN-FXN     0.0      1.0\n",
       "2        CNN        HFP     CNN-HFP     0.0      1.0\n",
       "3        CNN        NBC     CNN-NBC     0.0      1.0\n",
       "4        CNN        NYT     CNN-NYT     0.0      1.0\n",
       "5        CNN        RET     CNN-RET     0.0      1.0\n",
       "6        CNN        WPO     CNN-WPO     0.0      1.0\n",
       "7        CNN        WSJ     CNN-WSJ     0.0      1.0\n",
       "8        CTB        CNN     CTB-CNN     0.0      1.0\n",
       "9        CTB        FXN     CTB-FXN     0.0      1.0\n",
       "10       CTB        HFP     CTB-HFP     0.0      1.0\n",
       "11       CTB        NBC     CTB-NBC     0.0      1.0\n",
       "12       CTB        NYT     CTB-NYT     0.0      1.0\n",
       "13       CTB        RET     CTB-RET     0.0      1.0\n",
       "14       CTB        WPO     CTB-WPO     0.0      1.0\n",
       "15       CTB        WSJ     CTB-WSJ     0.0      1.0\n",
       "16       FXN        CNN     FXN-CNN     0.0      1.0\n",
       "17       FXN        CTB     FXN-CTB     0.0      1.0\n",
       "18       FXN        HFP     FXN-HFP     0.0      1.0\n",
       "19       FXN        NBC     FXN-NBC     0.0      1.0\n",
       "20       FXN        NYT     FXN-NYT     0.0      1.0\n",
       "21       FXN        RET     FXN-RET     0.0      1.0\n",
       "22       FXN        WPO     FXN-WPO     0.0      1.0\n",
       "23       FXN        WSJ     FXN-WSJ     0.0      1.0\n",
       "24       HFP        CNN     HFP-CNN     0.0      1.0\n",
       "25       HFP        CTB     HFP-CTB     0.0      1.0\n",
       "26       HFP        FXN     HFP-FXN     0.0      1.0\n",
       "27       HFP        NBC     HFP-NBC     0.0      1.0\n",
       "28       HFP        NYT     HFP-NYT     0.0      1.0\n",
       "29       HFP        RET     HFP-RET     0.0      1.0\n",
       "30       HFP        WPO     HFP-WPO     0.0      1.0\n",
       "31       HFP        WSJ     HFP-WSJ     0.0      1.0\n",
       "32       NBC        CNN     NBC-CNN     0.0      1.0\n",
       "33       NBC        CTB     NBC-CTB     0.0      1.0\n",
       "34       NBC        FXN     NBC-FXN     0.0      1.0\n",
       "35       NBC        HFP     NBC-HFP     0.0      1.0\n",
       "36       NBC        NYT     NBC-NYT     0.0      1.0\n",
       "37       NBC        RET     NBC-RET     0.0      1.0\n",
       "38       NBC        WPO     NBC-WPO     0.0      1.0\n",
       "39       NBC        WSJ     NBC-WSJ     0.0      1.0\n",
       "40       NYT        CNN     NYT-CNN     0.0      1.0\n",
       "41       NYT        CTB     NYT-CTB     0.0      1.0\n",
       "42       NYT        FXN     NYT-FXN     0.0      1.0\n",
       "43       NYT        HFP     NYT-HFP     0.0      1.0\n",
       "44       NYT        NBC     NYT-NBC     0.0      1.0\n",
       "45       NYT        RET     NYT-RET     0.0      1.0\n",
       "46       NYT        WPO     NYT-WPO     0.0      1.0\n",
       "47       NYT        WSJ     NYT-WSJ     0.0      1.0\n",
       "48       RET        CNN     RET-CNN     0.0      1.0\n",
       "49       RET        CTB     RET-CTB     0.0      1.0\n",
       "50       RET        FXN     RET-FXN     0.0      1.0\n",
       "51       RET        HFP     RET-HFP     0.0      1.0\n",
       "52       RET        NBC     RET-NBC     0.0      1.0\n",
       "53       RET        NYT     RET-NYT     0.0      1.0\n",
       "54       RET        WPO     RET-WPO     0.0      1.0\n",
       "55       RET        WSJ     RET-WSJ     0.0      1.0\n",
       "56       WPO        CNN     WPO-CNN     0.0      1.0\n",
       "57       WPO        CTB     WPO-CTB     0.0      1.0\n",
       "58       WPO        FXN     WPO-FXN     0.0      1.0\n",
       "59       WPO        HFP     WPO-HFP     0.0      1.0\n",
       "60       WPO        NBC     WPO-NBC     0.0      1.0\n",
       "61       WPO        NYT     WPO-NYT     0.0      1.0\n",
       "62       WPO        RET     WPO-RET     0.0      1.0\n",
       "63       WPO        WSJ     WPO-WSJ     0.0      1.0\n",
       "64       WSJ        CNN     WSJ-CNN     0.0      1.0\n",
       "65       WSJ        CTB     WSJ-CTB     0.0      1.0\n",
       "66       WSJ        FXN     WSJ-FXN     0.0      1.0\n",
       "67       WSJ        HFP     WSJ-HFP     0.0      1.0\n",
       "68       WSJ        NBC     WSJ-NBC     0.0      1.0\n",
       "69       WSJ        NYT     WSJ-NYT     0.0      1.0\n",
       "70       WSJ        RET     WSJ-RET     0.0      1.0\n",
       "71       WSJ        WPO     WSJ-WPO     0.0      1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(RESULTS_PATH + TOPIC_OF_INTEREST)\\ndf.reset_index()\\ndf\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(RESULTS_PATH + TOPIC_OF_INTEREST)\\ndf.reset_index()\\ndf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(RESULTS_PATH + TOPIC_OF_INTEREST)\n",
    "df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# only necessary to run, if result csv is imported.\\n# \\\"\\\"\\\"\\ndf[\\\"reference\\\"] = 1\\ndf[\\\"comparison\\\"] = 1\\ndf[\\\"ones\\\"] = 1\\nfor i in range(len(df)):\\n    df.reference[i] = df.combination[i][:3]\\n    df.comparison[i] = df.combination[i][-3:]\\n# \\\"\\\"\\\"\\ndf[\\\"same_chi\\\"] = 1\\ndf[\\\"same_lit\\\"] = 1\";\n",
       "                var nbb_formatted_code = \"# only necessary to run, if result csv is imported.\\n# \\\"\\\"\\\"\\ndf[\\\"reference\\\"] = 1\\ndf[\\\"comparison\\\"] = 1\\ndf[\\\"ones\\\"] = 1\\nfor i in range(len(df)):\\n    df.reference[i] = df.combination[i][:3]\\n    df.comparison[i] = df.combination[i][-3:]\\n# \\\"\\\"\\\"\\ndf[\\\"same_chi\\\"] = 1\\ndf[\\\"same_lit\\\"] = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only necessary to run, if result csv is imported.\n",
    "# \"\"\"\n",
    "df[\"reference\"] = 1\n",
    "df[\"comparison\"] = 1\n",
    "df[\"ones\"] = 1\n",
    "for i in range(len(df)):\n",
    "    df.reference[i] = df.combination[i][:3]\n",
    "    df.comparison[i] = df.combination[i][-3:]\n",
    "# \"\"\"\n",
    "df[\"same_chi\"] = 1\n",
    "df[\"same_lit\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# add labels for evaluating accuracy, precision and recall\\nliberal = [\\\"NYT\\\", \\\"HFP\\\", \\\"WPO\\\"]\\ncenter = [\\\"CNN\\\", \\\"RET\\\", \\\"NBC\\\"]\\nconservative = [\\\"CTB\\\", \\\"FXN\\\", \\\"WSJ\\\"]\\n\\n\\nfor i in range(len(df)):\\n    # adding labels, derived from the chi-test\\n    if df.p_value[i] <= 0.05:\\n        df.same_chi[i] = 1\\n    else:\\n        df.same_chi[i] = 0\\n    \\n    # adding labels, derived from literature\\n    if all(x in liberal for x in [df.reference[i], df.comparison[i]]) == True:\\n        df.same_lit[i] = 1\\n    elif all(x in center for x in [df.reference[i], df.comparison[i]]) == True:\\n        df.same_lit[i] = 1\\n    elif all(x in conservative for x in [df.reference[i], df.comparison[i]]) == True:\\n        df.same_lit[i] = 1\\n    else:\\n        df.same_lit[i] = 0\";\n",
       "                var nbb_formatted_code = \"# add labels for evaluating accuracy, precision and recall\\nliberal = [\\\"NYT\\\", \\\"HFP\\\", \\\"WPO\\\"]\\ncenter = [\\\"CNN\\\", \\\"RET\\\", \\\"NBC\\\"]\\nconservative = [\\\"CTB\\\", \\\"FXN\\\", \\\"WSJ\\\"]\\n\\n\\nfor i in range(len(df)):\\n    # adding labels, derived from the chi-test\\n    if df.p_value[i] <= 0.05:\\n        df.same_chi[i] = 1\\n    else:\\n        df.same_chi[i] = 0\\n\\n    # adding labels, derived from literature\\n    if all(x in liberal for x in [df.reference[i], df.comparison[i]]) == True:\\n        df.same_lit[i] = 1\\n    elif all(x in center for x in [df.reference[i], df.comparison[i]]) == True:\\n        df.same_lit[i] = 1\\n    elif all(x in conservative for x in [df.reference[i], df.comparison[i]]) == True:\\n        df.same_lit[i] = 1\\n    else:\\n        df.same_lit[i] = 0\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add labels for evaluating accuracy, precision and recall\n",
    "liberal = [\"NYT\", \"HFP\", \"WPO\"]\n",
    "center = [\"CNN\", \"RET\", \"NBC\"]\n",
    "conservative = [\"CTB\", \"FXN\", \"WSJ\"]\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # adding labels, derived from the chi-test\n",
    "    if df.p_value[i] <= 0.05:\n",
    "        df.same_chi[i] = 1\n",
    "    else:\n",
    "        df.same_chi[i] = 0\n",
    "    \n",
    "    # adding labels, derived from literature\n",
    "    if all(x in liberal for x in [df.reference[i], df.comparison[i]]) == True:\n",
    "        df.same_lit[i] = 1\n",
    "    elif all(x in center for x in [df.reference[i], df.comparison[i]]) == True:\n",
    "        df.same_lit[i] = 1\n",
    "    elif all(x in conservative for x in [df.reference[i], df.comparison[i]]) == True:\n",
    "        df.same_lit[i] = 1\n",
    "    else:\n",
    "        df.same_lit[i] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results hypothesis 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# split into two dataframes df_same and df_diff\\ndf_same = pd.DataFrame()\\ndf_diff = pd.DataFrame()\\n\\nfor i in range(len(df)):\\n    if all(x in liberal for x in [df.reference[i], df.comparison[i]]) == True:\\n        df_same = df_same.append(df.loc[i])\\n    elif all(x in center for x in [df.reference[i], df.comparison[i]]) == True:\\n        df_same = df_same.append(df.loc[i])\\n    elif all(x in conservative for x in [df.reference[i], df.comparison[i]]) == True:\\n        df_same = df_same.append(df.loc[i])\\n    else:\\n        df_diff = df_diff.append(df.loc[i])\\n\\ndf_same = df_same.reset_index()\\ndf_diff = df_diff.reset_index()\";\n",
       "                var nbb_formatted_code = \"# split into two dataframes df_same and df_diff\\ndf_same = pd.DataFrame()\\ndf_diff = pd.DataFrame()\\n\\nfor i in range(len(df)):\\n    if all(x in liberal for x in [df.reference[i], df.comparison[i]]) == True:\\n        df_same = df_same.append(df.loc[i])\\n    elif all(x in center for x in [df.reference[i], df.comparison[i]]) == True:\\n        df_same = df_same.append(df.loc[i])\\n    elif all(x in conservative for x in [df.reference[i], df.comparison[i]]) == True:\\n        df_same = df_same.append(df.loc[i])\\n    else:\\n        df_diff = df_diff.append(df.loc[i])\\n\\ndf_same = df_same.reset_index()\\ndf_diff = df_diff.reset_index()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into two dataframes df_same and df_diff\n",
    "df_same = pd.DataFrame()\n",
    "df_diff = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if all(x in liberal for x in [df.reference[i], df.comparison[i]]) == True:\n",
    "        df_same = df_same.append(df.loc[i])\n",
    "    elif all(x in center for x in [df.reference[i], df.comparison[i]]) == True:\n",
    "        df_same = df_same.append(df.loc[i])\n",
    "    elif all(x in conservative for x in [df.reference[i], df.comparison[i]]) == True:\n",
    "        df_same = df_same.append(df.loc[i])\n",
    "    else:\n",
    "        df_diff = df_diff.append(df.loc[i])\n",
    "\n",
    "df_same = df_same.reset_index()\n",
    "df_diff = df_diff.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        diff     0.0000    0.0000    0.0000       0.0\n",
      "        same     0.0000    0.0000    0.0000      18.0\n",
      "\n",
      "    accuracy                         0.0000      18.0\n",
      "   macro avg     0.0000    0.0000    0.0000      18.0\n",
      "weighted avg     0.0000    0.0000    0.0000      18.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Results for Hyp 1.1\\ny_true = df_same.same_lit\\ny_pred = df_same.same_chi\\n\\ntarget_names = [\\\"diff\\\", \\\"same\\\"]\\nprint(classification_report(y_true, y_pred, target_names=target_names, digits=4))\";\n",
       "                var nbb_formatted_code = \"# Results for Hyp 1.1\\ny_true = df_same.same_lit\\ny_pred = df_same.same_chi\\n\\ntarget_names = [\\\"diff\\\", \\\"same\\\"]\\nprint(classification_report(y_true, y_pred, target_names=target_names, digits=4))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results for Hyp 1.1\n",
    "y_true = df_same.same_lit\n",
    "y_pred = df_same.same_chi\n",
    "\n",
    "target_names = [\"diff\", \"same\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results hypothesis 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-edabfd854d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"diff\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"same\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1993\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m                 \u001b[0;34m\"parameter\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m             )\n\u001b[1;32m   1997\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 1, does not match size of target_names, 2. Try specifying the labels parameter"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Results for Hyp 1.2\\ny_true = df_diff.same_lit\\ny_pred = df_diff.same_chi\\n\\ntarget_names = [\\\"diff\\\", \\\"same\\\"]\\nprint(classification_report(y_true, y_pred, target_names=target_names, digits=4))\";\n",
       "                var nbb_formatted_code = \"# Results for Hyp 1.2\\ny_true = df_diff.same_lit\\ny_pred = df_diff.same_chi\\n\\ntarget_names = [\\\"diff\\\", \\\"same\\\"]\\nprint(classification_report(y_true, y_pred, target_names=target_names, digits=4))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results for Hyp 1.2\n",
    "y_true = df_diff.same_lit\n",
    "y_pred = df_diff.same_chi\n",
    "\n",
    "target_names = [\"diff\", \"same\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        diff     0.7500    1.0000    0.8571        54\n",
      "        same     0.0000    0.0000    0.0000        18\n",
      "\n",
      "    accuracy                         0.7500        72\n",
      "   macro avg     0.3750    0.5000    0.4286        72\n",
      "weighted avg     0.5625    0.7500    0.6429        72\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Results for overall precision\\ny_true = df.same_lit\\ny_pred = df.same_chi\\n\\ntarget_names = [\\\"diff\\\", \\\"same\\\"]\\nprint(classification_report(y_true, y_pred, target_names=target_names, digits=4))\";\n",
       "                var nbb_formatted_code = \"# Results for overall precision\\ny_true = df.same_lit\\ny_pred = df.same_chi\\n\\ntarget_names = [\\\"diff\\\", \\\"same\\\"]\\nprint(classification_report(y_true, y_pred, target_names=target_names, digits=4))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results for overall precision\n",
    "y_true = df.same_lit\n",
    "y_pred = df.same_chi\n",
    "\n",
    "target_names = [\"diff\", \"same\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Hypothesis 2 <a class=\"anchor\" id=\"hyp2\"></a>\n",
    "\n",
    "Goal of hypothesis 2 estimates whether there are other possibilities to categorize news-outlets into similar slant groups. \n",
    "Therefore a graph is constructed from the news-outlets. The news-outlets are represented by nodes, the edges by the chi-value of the news-outlet tuples. The chi-statistic was chosen, since it respects differences in the number of articles of the compared news-outlets.\n",
    "\n",
    "The graphs were constructed as directed and undirected graphs.\n",
    "For each Version the local clustering coefficient of each node was calculated after Opsahl and Panzarasa (2009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize as directed weighted graph\n",
    "G_weighted = nx.Graph()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    G_weighted.add_edge(df.reference[i], df.comparison[i], weight=(df.chi_sq[i] * 70))\n",
    "\n",
    "nx.spring_layout(G_weighted)\n",
    "plt.figure(figsize=(6, 6))\n",
    "nx.draw_networkx(G_weighted, with_labels=True, edge_color=\"gray\", node_color=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as undirected weighted graph.\n",
    "# The edge, weights are combined and averaged \n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "G_new = nx.Graph()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    k = pd.DataFrame()\n",
    "    for j in range(len(df)):\n",
    "        if (\n",
    "            df.reference[i] == df.comparison[j]\n",
    "            and df.reference[j] == df.comparison[i]\n",
    "            and i != j\n",
    "        ):\n",
    "            l = [\n",
    "                str(df.reference[i]),\n",
    "                str(df.comparison[i]),\n",
    "                ((df.chi_sq[i] + df.chi_sq[j])),\n",
    "            ]\n",
    "                      \n",
    "            G_new.add_edge(\n",
    "                str(df.reference[i]),\n",
    "                str(df.comparison[i]),\n",
    "                weight=(((df.chi_sq[i]+df.chi_sq[j])/2)*80),\n",
    "            )\n",
    "            \n",
    "            k = k.append(l)\n",
    "            k = k.transpose()\n",
    "            df_new = df_new.append(k)\n",
    "\n",
    "nx.spring_layout(G_new)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.axis = \"off\"\n",
    "nx.draw_networkx(G_new, with_labels=True, edge_color=\"gray\", node_color=\"white\")\n",
    "\n",
    "df_new = df_new.rename(columns={0: \"reference\", 1: \"comparison\", 2: \"summed_chi_sq\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the clustering coefficient for each node\n",
    "# normal cluster coefficient not useful since interconnected and weighted --> therefore Opsahl et al. (2009)\n",
    "\n",
    "# triplet values - arithmetic, geometric, max, min --> best results with geometric\n",
    "\n",
    "# split into list of dfs containing only one reference node\n",
    "df_list = [df.loc[i : i + 8 - 1, :] for i in range(0, len(df), 8)]\n",
    "\n",
    "df_coefficient = pd.DataFrame()\n",
    "\n",
    "# loop over every single node\n",
    "for df_single in df_list:\n",
    "    df_single = df_single.reset_index()\n",
    "    total_value = 0\n",
    "\n",
    "    # loop over the weights of all connected nodes\n",
    "    for j in range(len(df_single) - 1):\n",
    "        # geometric\n",
    "        # total_value = total_value + math.sqrt(           df_single.chi_sq[j] * df_single.chi_sq[j + 1]        )\n",
    "        # arithmetic\n",
    "        # total_value = total_value + (        (df_single.chi_sq[j] * df_single.chi_sq[j + 1]) / 2      )\n",
    "        # max\n",
    "        # total_value = total_value + max(df_single.chi_sq[j], df_single.chi_sq[j + 1])\n",
    "        # min\n",
    "        total_value = total_value + min(df_single.chi_sq[j], df_single.chi_sq[j + 1])\n",
    "\n",
    "    for i in range(len(df_single) - 1):\n",
    "        # geometric\n",
    "        # triplet_value = math.sqrt(df_single.chi_sq[i] * df_single.chi_sq[i + 1])\n",
    "        # arithmetic\n",
    "        # triplet_value = (df_single.chi_sq[i] * df_single.chi_sq[i + 1]) / 2\n",
    "        # max\n",
    "        # triplet_value = max(df_single.chi_sq[i], df_single.chi_sq[i + 1])\n",
    "        # min\n",
    "        triplet_value = min(df_single.chi_sq[i], df_single.chi_sq[i + 1])\n",
    "\n",
    "        cluster_coefficient = triplet_value / total_value\n",
    "        buffer = [\n",
    "            [\n",
    "                df_single.reference[i],\n",
    "                df_single.comparison[i],\n",
    "                df_single.comparison[i + 1],\n",
    "                triplet_value,\n",
    "                cluster_coefficient,\n",
    "            ]\n",
    "        ]\n",
    "        df_coefficient = df_coefficient.append(buffer)\n",
    "\n",
    "df_coefficient = df_coefficient.reset_index()\n",
    "\n",
    "\n",
    "check_list = []\n",
    "# print out triangles that have a cluster coefficient bigger, than X\n",
    "for i in range(len(df_coefficient)):\n",
    "    if df_coefficient[4][i] >= ((0.5) * df_coefficient[4].max()):\n",
    "        print(list(df_coefficient.loc[i][1:4]))\n",
    "        check_list.append(list(df_coefficient.loc[i][1:4]))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether there is a correctly predicted triple\n",
    "liberal = [\"NYT\", \"HFP\", \"WPO\"]\n",
    "center = [\"CNN\", \"RET\", \"NBC\"]\n",
    "conservative = [\"CTB\", \"FXN\", \"WSJ\"]\n",
    "\n",
    "liberal.sort()\n",
    "center.sort()\n",
    "conservative.sort()\n",
    "\n",
    "# check_list.append([\"NYT\", \"HFP\", \"WPO\"])\n",
    "\n",
    "i = 0\n",
    "for element in check_list:\n",
    "    element.sort()\n",
    "    if element == liberal:\n",
    "        print(\"tatache - liberal \" + str(element))\n",
    "        i += 1\n",
    "    elif element == center:\n",
    "        print(\"tatsache - center \" + str(element))\n",
    "        i += 1\n",
    "    elif element == conservative:\n",
    "        print(\"tatsache - conservative \" + str(element))\n",
    "        i += 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "accuracy = i / (3 * 3 * 3)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
