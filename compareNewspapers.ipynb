{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretty code\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from newsrelations.query_db.relation_query import DBQueryHandlerCoocc\n",
    "from newsrelations.helper_classes.synonym_handler import SynonymHandler\n",
    "from newsrelations.metrics.distances import DistanceMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contingency_table_from_single_topic(\n",
    "    relation_models_path, relation_models, topic_of_interest, no_entities=10\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined topic [TOPIC_OF_INTEREST].\n",
    "    The first model in [RELATION_MODELS] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [NO_ENTITIES] co_occuring entities from the model and builds a contingency table.\n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_of_interest = str           \n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # initialize DistanceMeasure with reference-model\n",
    "    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest, cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\n",
    "    )\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(\n",
    "        np.array([t[1] for t in top]),\n",
    "        index=[t[0] for t in top],\n",
    "        columns=[str(relation_models[0])],\n",
    "    )\n",
    "\n",
    "    # loop through all remaining models\n",
    "    for model in relation_models[1:]:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        # buffer for cooccurrences\n",
    "        co_occs = []\n",
    "        # loop through all entities and get number of co-occurrences\n",
    "        for row in contingency_table.index:\n",
    "            co_occs.append(\n",
    "                len(\n",
    "                    list(\n",
    "                        db_handler.select_relations(\n",
    "                            e1=topic_of_interest.lower(),\n",
    "                            e2=row.lower(),\n",
    "                            e1_is_synset=0,\n",
    "                            e2_is_synset=0,\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        contingency_table[str(model)] = co_occs\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_models(relation_models):\n",
    "    \"\"\"\n",
    "    This function lists the models from the relation_models list and their counter index\n",
    "    \n",
    "    Input: relation_models = list\n",
    "    \n",
    "    Output: None\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for model in relation_models:\n",
    "        print(\"model (\" + str(i) + \"): \" + str(model))\n",
    "        i += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contingency_table_from_topic_list(\n",
    "    relation_models_path, relation_models, topic_of_interest_list, no_entities=10\n",
    "):\n",
    "    \"\"\"\n",
    "    This function builds a contingency table from a input list of relation models generated with relation_miner.py \n",
    "    in regards to predetermined topic list [topic_of_interest_list].\n",
    "    The first model in [relation_models] is the reference model all other models will be compared with.\n",
    "    The function extracts the top [no_entities] co-occuring entities for the first [topic_of_interest] from the \n",
    "    model and builds a contingency table.\n",
    "    \n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_of_interest_list = list           \n",
    "            no_entities = int (standard 10)\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # identifier for models in relation_models_list\n",
    "    i = 0\n",
    "    # print models with idx \n",
    "    explain_models(relation_models)\n",
    "    \n",
    "    # initialize DistanceMeasure with reference-model\n",
    "    dm = DistanceMeasure(relation_models_path, str(relation_models[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "    top = dm.get_top_co_occurrences(\n",
    "        topic_of_interest_list[0], cutoff=no_entities, e1_is_synset=0, e2_is_synset=0\n",
    "    )\n",
    "    # write first row of contingency_table\n",
    "    contingency_table = pd.DataFrame(\n",
    "        np.array([t[1] for t in top]),\n",
    "        index=[t[0] for t in top],\n",
    "        columns=[str(topic_of_interest_list[0]) + \" (\" + str(i) + \")\"],\n",
    "    )\n",
    "\n",
    "    # loop through the models\n",
    "    for model in relation_models[:]:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        for topic in topic_of_interest_list:\n",
    "            # buffer for co-occurrencces\n",
    "            co_occs = []\n",
    "\n",
    "            # loop through all all entities and get number of co-occurrences\n",
    "            for row in contingency_table.index:\n",
    "                co_occs.append(\n",
    "                    len(\n",
    "                        list(\n",
    "                            db_handler.select_relations(\n",
    "                                e1=topic.lower(),\n",
    "                                e2=row.lower(),\n",
    "                                e1_is_synset=0,\n",
    "                                e2_is_synset=0,\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            contingency_table[str(topic) + \" (\" + str(i) + \")\"] = co_occs\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entity_lists(\n",
    "    relation_models_path, relation_models, topic_list1, topic_list2\n",
    "):\n",
    "    \"\"\"\n",
    "    This function creates a contingency table from a two input lists of entities [topic_list1][topic_list2]\n",
    "    from a list of relation models \n",
    "    \n",
    "    input:  relation_models = list\n",
    "            relation_models_path = str \n",
    "            topic_list1 = list           \n",
    "            topic_list2 = list\n",
    "            \n",
    "    output: contingency_table = pandas DataFrame [rows = different models, columns = entities]\n",
    "    \"\"\"\n",
    "    # idx for models\n",
    "    i = 0\n",
    "    \n",
    "    # print models with idx \n",
    "    explain_models(relation_models)\n",
    "\n",
    "    # initialize contingency_table\n",
    "    contingency_table = pd.DataFrame(index=topic_list2)\n",
    "\n",
    "    # loop through the models\n",
    "    for model in relation_models:\n",
    "        # initialize db_handler()\n",
    "        db_handler = DBQueryHandlerCoocc(relation_models_path, model)\n",
    "\n",
    "        for topic1 in topic_list1:\n",
    "            # buffer for co-occurrencces\n",
    "            co_occs = []\n",
    "\n",
    "            # loop through all all entities and get number of co-occurrences\n",
    "            for topic2 in topic_list2:\n",
    "                co_occs.append(\n",
    "                    len(\n",
    "                        list(\n",
    "                            db_handler.select_relations(\n",
    "                                e1=topic1.lower(),\n",
    "                                e2=topic2.lower(),\n",
    "                                e1_is_synset=0,\n",
    "                                e2_is_synset=0,\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            contingency_table[str(topic1) + \" (\" + str(i) + \")\"] = co_occs\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # transpose the contingency table to get it into the right format\n",
    "    contingency_table = contingency_table.transpose()\n",
    "\n",
    "    return contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_squared(contingency_table):\n",
    "    \"\"\"\n",
    "    This function conducts a chi-squared test of independence between the different rows of a contingency table\n",
    "    \n",
    "    input: contingency_table\n",
    "    \n",
    "    ouput: None\n",
    "    \"\"\"\n",
    "    contingency_table = sm.stats.Table(contingency_table)\n",
    "    results = contingency_table.test_nominal_association()\n",
    "    \n",
    "    \n",
    "    # orig contingency table\n",
    "    print(\"Original contingency table:\")\n",
    "    print(contingency_table.table_orig)\n",
    "    # expected values\n",
    "    print(\"\\nExpected values:\")\n",
    "    print(contingency_table.fittedvalues)\n",
    "    # residual \n",
    "    print(\"\\nChi-square contributions:\")\n",
    "    print(contingency_table.chi2_contribs)\n",
    "    print(\"\\nResults:\")\n",
    "    \n",
    "    print(results)\n",
    "    \n",
    "    \n",
    "    results = contingency_table.test_ordinal_association()\n",
    "    #print(\"\\nOrdinal test results:\")\n",
    "    #print(results)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "\n",
    "Variable setups for different runs of models (all scraped from commoncrawl.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Try \n",
    "# general tryout on the NewsRelations Library\n",
    "\n",
    "# directory path of relation models \n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/firstTry\"\n",
    "\n",
    "# model name\n",
    "RELATION_MODELS = [\n",
    "    \"model.sqlite\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Try\n",
    "# models from newssources with different biases \n",
    "#\n",
    "# -year:    2008 (for foxnews 2o08-2010)\n",
    "# -domain:  politics\n",
    "# -sources: NYT & foxnews \n",
    "\n",
    "# directory path of relation models \n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/secondTry\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RMadvanced_2008_politics_nytimes.sqlite\",\n",
    "    \"RM_2009_politics_nytimes.sqlite\",\n",
    "    \"RM_2008-2010_politics_foxnews.sqlite\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Try\n",
    "# models from newssources with different biases \n",
    "#\n",
    "# -year:    2011\n",
    "# -domain:  news\n",
    "# -sources: reuters & national public radio\n",
    "\n",
    "# directory path of relation models \n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/thirdTry\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2011_news_reuters.sqlite\",\n",
    "    \"RM_2011_news_npr.sqlite\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth try\n",
    "# two models from newssources with different biases each, for comparing slant coherence within\n",
    "# different directions. Timeslots with gapless news reporting were chosen.\n",
    "#\n",
    "# -year:    2011-01-01 - 2011-03-31\n",
    "# -domain:  news\n",
    "# -sources(left):    New York Times (NYT) 637, Washington Post (WP) 508\n",
    "#         (center):  National Public Radio (NPR) 109, Reuters (RET) 300\n",
    "#         (right):   FoxNews (FN) 2735, Newsmax (NM) 180\n",
    "\n",
    "# directory path of relation models\n",
    "RELATION_MODELS_PATH = \"/home/jonas/Documents/GitHub/MasterThesis/models/fourthTry\"\n",
    "\n",
    "# model names\n",
    "RELATION_MODELS = [\n",
    "    \"RM_2011_news_NYT.sqlite\",\n",
    "    \"RM_2011_news_WP.sqlite\",\n",
    "    \"RM_2011_news_RET.sqlite\",\n",
    "    \"RM_2011_news_NPR.sqlite\",\n",
    "    \"RM_2011_news_FN.sqlite\",\n",
    "    \"RM_2011_news_NM.sqlite\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of entities you want to compare\n",
    "NO_ENTITIES = 5\n",
    "\n",
    "# reference entity\n",
    "TOPIC_OF_INTEREST = \"united_states\"\n",
    "\n",
    "# reference entity list\n",
    "TOPIC_OF_INTEREST_LIST = [\n",
    "    \"united_states\", \n",
    "    \"germany\", \n",
    "    \"russia\", \n",
    "    \"india\", \n",
    "    \"china\"\n",
    "]\n",
    "\n",
    "# co-occurrence entity list\n",
    "TOPIC_OF_INTEREST_LIST2 = [\n",
    "    \"united_states\",\n",
    "    \"united_states\",\n",
    "    \"united_states\",\n",
    "    \"united_states\",\n",
    "    \"united_states\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original contingency table:\n",
      "                             reuters  u.s.  washington  new_york  china\n",
      "RM_2011_news_reuters.sqlite     1725  1286         724       478    399\n",
      "RM_2011_news_npr.sqlite            3   388         247       126     88\n",
      "\n",
      "Expected values:\n",
      "                                 reuters         u.s.  washington    new_york  \\\n",
      "RM_2011_news_reuters.sqlite  1458.553441  1412.973646   819.59224  509.818448   \n",
      "RM_2011_news_npr.sqlite       269.446559   261.026354   151.40776   94.181552   \n",
      "\n",
      "                                  china  \n",
      "RM_2011_news_reuters.sqlite  411.062225  \n",
      "RM_2011_news_npr.sqlite       75.937775  \n",
      "\n",
      "Chi-square contributions:\n",
      "                                reuters       u.s.  washington   new_york  \\\n",
      "RM_2011_news_reuters.sqlite   48.674095  11.410196   11.149296   1.985832   \n",
      "RM_2011_news_npr.sqlite      263.479961  61.765053   60.352761  10.749596   \n",
      "\n",
      "                                china  \n",
      "RM_2011_news_reuters.sqlite  0.353954  \n",
      "RM_2011_news_npr.sqlite      1.916007  \n",
      "\n",
      "Results:\n",
      "df          4\n",
      "pvalue      0.0\n",
      "statistic   471.83675172358085\n"
     ]
    }
   ],
   "source": [
    "# extracting a contingency table from a single reference entity \n",
    "contingency_table = build_contingency_table_from_single_topic(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS, TOPIC_OF_INTEREST, NO_ENTITIES\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original contingency table:\n",
      "                   reuters  u.s.  washington  new_york  china\n",
      "united_states (0)     1725  1286         724       478    399\n",
      "germany (0)            327   175          56        84    112\n",
      "russia (0)             274   140          65        42    136\n",
      "india (0)              282   178          64        73    181\n",
      "china (0)              812   484         201       210    518\n",
      "united_states (1)        3   388         247       126     88\n",
      "germany (1)              2    55          32        26     19\n",
      "russia (1)               2    48          28        17     26\n",
      "india (1)                0    58          33        26     55\n",
      "china (1)                1   123          63        35    105\n",
      "\n",
      "Expected values:\n",
      "                       reuters         u.s.  washington    new_york  \\\n",
      "united_states (0)  1487.161251  1273.098519  656.285540  484.514837   \n",
      "germany (0)         243.130872   208.134493  107.293863   79.211662   \n",
      "russia (0)          211.852763   181.358570   93.490806   69.021303   \n",
      "india (0)           250.869786   214.759464  110.709052   81.732988   \n",
      "china (0)           717.461792   614.189984  316.616506  233.747943   \n",
      "united_states (1)   274.731437   235.186457  121.239219   89.507077   \n",
      "germany (1)          43.208935    36.989419   19.068140   14.077404   \n",
      "russia (1)           39.017023    33.400893   17.218246   12.711686   \n",
      "india (1)            55.623442    47.616976   24.546673   18.122032   \n",
      "china (1)           105.442699    90.265225   46.531954   34.353068   \n",
      "\n",
      "                        china  \n",
      "united_states (0)  710.939854  \n",
      "germany (0)        116.229109  \n",
      "russia (0)         101.276558  \n",
      "india (0)          119.928709  \n",
      "china (0)          342.983776  \n",
      "united_states (1)  131.335810  \n",
      "germany (1)         20.656102  \n",
      "russia (1)          18.652151  \n",
      "india (1)           26.590877  \n",
      "china (1)           50.407054  \n",
      "\n",
      "Chi-square contributions:\n",
      "                      reuters       u.s.  washington   new_york       china\n",
      "united_states (0)   38.037079   0.130743    6.986666   0.087599  136.870190\n",
      "germany (0)         28.931047   5.274929   24.522003   0.289455    0.153880\n",
      "russia (0)          18.230959   9.431765    8.682416  10.578630   11.905198\n",
      "india (0)            3.862921   6.291961   19.706930   0.933100   31.099331\n",
      "china (0)           12.457071  27.596399   42.218824   2.412705   89.306494\n",
      "united_states (1)  268.764196  99.291343  130.450971  14.878526   14.299165\n",
      "germany (1)         39.301508   8.769562    8.770284  10.097621    0.132778\n",
      "russia (1)          35.119543   6.381084    6.751339   1.446672    2.894619\n",
      "india (1)           54.627937   2.264049    2.911137   3.424693   30.351698\n",
      "china (1)          103.452183  11.871300    5.828179   0.012183   59.126442\n",
      "\n",
      "Results:\n",
      "df          36\n",
      "pvalue      0.0\n",
      "statistic   1457.2173064370738\n"
     ]
    }
   ],
   "source": [
    "# extract a contingency table from a list of reference entities \n",
    "contingency_table = build_contingency_table_from_topic_list(\n",
    "    RELATION_MODELS_PATH, RELATION_MODELS, TOPIC_OF_INTEREST_LIST, NO_ENTITIES)\n",
    "\n",
    "chi_squared(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model (0): RM_2011_news_reuters.sqlite\n",
      "model (1): RM_2011_news_npr.sqlite\n"
     ]
    }
   ],
   "source": [
    "# extract a contingency table from two lists of entities \n",
    "\n",
    "contingency_table = compare_entity_lists(\n",
    "    RELATION_MODELS_PATH,\n",
    "    RELATION_MODELS,\n",
    "    TOPIC_OF_INTEREST_LIST,\n",
    "    TOPIC_OF_INTEREST_LIST2,\n",
    ")\n",
    "\n",
    "chi_squared(contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # initialize DistanceMeasure with reference-model\n",
    "dm = DistanceMeasure(RELATION_MODELS_PATH, str(RELATION_MODELS[0]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "topNYT = dm.get_top_co_occurrences(\n",
    "    TOPIC_OF_INTEREST, cutoff=10, e1_is_synset=0, e2_is_synset=0\n",
    ")\n",
    "\n",
    "dm = DistanceMeasure(RELATION_MODELS_PATH, str(RELATION_MODELS[1]))\n",
    "\n",
    "    # extract top NO_ENTITIES entities\n",
    "topFN = dm.get_top_co_occurrences(\n",
    "    TOPIC_OF_INTEREST, cutoff=10, e1_is_synset=0, e2_is_synset=0\n",
    ")\n",
    "\n",
    "\n",
    "print(topNYT)\n",
    "print(topFN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
